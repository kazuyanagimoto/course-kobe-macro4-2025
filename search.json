[
  {
    "objectID": "lecture/10-1-julia-intro.html",
    "href": "lecture/10-1-julia-intro.html",
    "title": "Juliaの基礎",
    "section": "",
    "text": "数値計算をする上でプログラミング言語の選択はとても重要です. 経済学でよく使われるプログラミング言語は速度の意味で概ね以下のような関係があります.\n\\[\n\\text{C/C++, Fortran, Julia} \\gg \\text{Python, Matlab} &gt; \\text{R}\n\\]\n\n\n\n\n\n\nFigure 1: Julia Micro Benchmarks\n\n\n\nおおむね, C/C++, Fortran, Juliaは10-100倍ほどPython, Matlab, Rより速く計算が可能です. なおベクトル化というテクニックやPythonのNumbaを用いることで, Python, Matlab, Rでも同様の速度も出すことが可能ですが, C/C++, Fortran, Juliaなどの言語とはそもそも質的に異なるという事実は頭に入れておいた方が良いでしょう.\n\n\n\nJuliaはC並の速さとPython, Matlab, Rの使いやすさを目指して開発された比較的新しい言語です (Bezanson et al. 2012). 私自身, 高速化のためにはある程度の前提知識が必要なものの, C/C++, Fortranよりもデバックが容易であるため, 数値計算においてはJuliaを使っています.\nまた, 無料かつオープンソースであるため, アカデミアを離れたとしても使い続けることができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#なぜjuliaを使うのか",
    "href": "lecture/10-1-julia-intro.html#なぜjuliaを使うのか",
    "title": "Juliaの基礎",
    "section": "",
    "text": "数値計算をする上でプログラミング言語の選択はとても重要です. 経済学でよく使われるプログラミング言語は速度の意味で概ね以下のような関係があります.\n\\[\n\\text{C/C++, Fortran, Julia} \\gg \\text{Python, Matlab} &gt; \\text{R}\n\\]\n\n\n\n\n\n\nFigure 1: Julia Micro Benchmarks\n\n\n\nおおむね, C/C++, Fortran, Juliaは10-100倍ほどPython, Matlab, Rより速く計算が可能です. なおベクトル化というテクニックやPythonのNumbaを用いることで, Python, Matlab, Rでも同様の速度も出すことが可能ですが, C/C++, Fortran, Juliaなどの言語とはそもそも質的に異なるという事実は頭に入れておいた方が良いでしょう.\n\n\n\nJuliaはC並の速さとPython, Matlab, Rの使いやすさを目指して開発された比較的新しい言語です (Bezanson et al. 2012). 私自身, 高速化のためにはある程度の前提知識が必要なものの, C/C++, Fortranよりもデバックが容易であるため, 数値計算においてはJuliaを使っています.\nまた, 無料かつオープンソースであるため, アカデミアを離れたとしても使い続けることができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#環境構築",
    "href": "lecture/10-1-julia-intro.html#環境構築",
    "title": "Juliaの基礎",
    "section": "環境構築",
    "text": "環境構築\n\nJulia\nJuliaupを用いたインストールを推奨します.\nWindows\nパワーシェルを開き, 以下のコマンドを実行します.\nwinget install julia -s msstore\nMac, Linux\nターミナルを開き, 以下のコマンドを実行します.\ncurl -sSL https://julialang.org/juliaup | bash\nなお, インストール後はパワーシェル/ターミナルで以下のコマンドを実行することで最新版のJuliaにアップデートすることができます.\njuliaup update"
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#関数-forループ-if文",
    "href": "lecture/10-1-julia-intro.html#関数-forループ-if文",
    "title": "Juliaの基礎",
    "section": "関数, forループ, if文",
    "text": "関数, forループ, if文\n\n関数\nfunction f(K, L; α)\n    return K^α * L^(1 - α)\nend\n\nf(0.3, 0.7, α=0.5)\n\nfunctionとendで囲まれた部分が関数の定義です.\n引数は()内に,で区切って列挙します.\n引数のうち, ; 以降はキーワード引数と呼ばれ, 呼び出す際に引数名を用いる必要があります.\n\nfunction f(K, L, A=1.0; α)\n    return A * K^α * L^(1 - α)\nend\n\nf(0.3, 0.7, α=1/3) # or equivalently, f(0.3, 0.7, 1.0, α = 1/3)\n\n引数にデフォルトの値を持たせることができます.\nデフォルトの値をもつ引数は, デフォルトを持たない引数の後に配置する必要があります.\n\n一行関数\nf(x, y) = 2x + y^2 + x * y\nf(1.0, 2.0)\n\nfunction-endを省略し, =によって関数を定義することができます.\nなお, 変数の前の数値の*は省略可能です.\n\n\n\nforループ\n\nfor i in 1:5\n    println(i)\nend\n\n1\n2\n3\n4\n5\n\n\n\nfor-endで囲まれた部分がforループです.\ninの後にイテレータを指定します.\n\nfor i in 1:5\n    for j in 1:3\n        println((i, j))\n    end\nend\n\n# Or equivalently\nfor i in 1:5, j in 1:3\n    println((i, j))\nend\n\n2次元のforループを行う場合は, for-endをネストするか,で区切って複数のイテレータを指定します.\n\n\n\nif文\nfunction f(x)\n    if x &gt; 0\n        return \"Positive\"\n    elseif x &lt; 0\n        return \"Negative\"\n    else\n        return \"Zero\"\n    end\nend\n\nif-endで囲まれた部分がif文です.\nelseifやelseを用いて条件分岐を行います."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#文字列と文字",
    "href": "lecture/10-1-julia-intro.html#文字列と文字",
    "title": "Juliaの基礎",
    "section": "文字列と文字",
    "text": "文字列と文字\n\nString と Character\nPythonやその他のプログラミング言語と異なり, Juliaでは文字列 (String) と文字 (Character) が厳密に区別されています.\n\n文字列はダブルクォーテーション \" で囲みます.\n文字 (1文字のみ) はシングルクォーテーション ' で囲みます.\n\n\ntypeof('a')\n\nChar\n\n\n\ntypeof(\"a\")\n\nString\n\n\nそのため, 以下のようなコードで直感的でない結果が得られることがあります.\n\n\"abcd\"[3] == \"c\"\n\nfalse\n\n\n\n\"abcd\"[3] == 'c'\n\ntrue\n\n\n\n\nUnicode文字\n\nJuliaではUnicode文字を変数名として使用することができます (e.g., α, ÷, σ², x₁).\nUnicode文字は\\ + 文字列 + &lt;tab&gt;で入力することができます. (e.g., \\alpha + &lt;tab&gt;で α が入力できます.)\n使用できるUnicode文字の一覧.\n\nそのため, CRRA効用関数とその導関数を以下のようにUnicode文字を用いて簡単に書くことができます.\n\\[\n\\begin{aligned}\nu(c, \\sigma) &= \\begin{cases}\n\\log c & \\text{ if } \\sigma = 1 \\\\\n\\frac{c^{1 - \\sigma}}{1 - \\sigma} & \\text{ if } \\sigma \\ne 1\n\\end{cases}\\\\\nu'(c, \\sigma) &= c^{-\\sigma}\n\\end{aligned}\n\\]\nu(c, σ) = σ == 1.0 ? log(c) : c^(1 - σ) / (1 - σ)\nu′(c, σ) = c^(-σ)\n\n導関数 u′　の上付き文字は \\prime + &lt;tab&gt; で入力できます.\n三項演算子 ? : を用いることで, if-else文を簡潔に書くことができます. つまり上のコードは以下と等価です.\n\nfunction u(c, σ)\n    if σ == 1.0\n        return log(c)\n    else\n        return c^(1 - σ) / (1 - σ)\n    end\nend\n\n\n文字列の内挿\n\nage = 26\nyears_stay = 6\nf(years, age) = 100years ÷ (age) # ÷ returns the quotient\n\ns = \"I came here $years_stay years ago, when I was $(age - years_stay).\\nSo I spent $(f(years_stay, age)) % of my life in Madrid.\"\nprintln(s)\n\nI came here 6 years ago, when I was 20.\nSo I spent 23 % of my life in Madrid.\n\n\n\n$ + 変数名 で変数を文字列内に埋め込むことができます.\n$(式) で式を文字列内に埋め込むことができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#データ構造",
    "href": "lecture/10-1-julia-intro.html#データ構造",
    "title": "Juliaの基礎",
    "section": "データ構造",
    "text": "データ構造\n\nタプル\n\nanimals = (\"bird\", \"cow\", \"fish\")\nanimals[1]\n\n\"bird\"\n\n\n\npars = (α=1.0, β=2.0, γ=4.0)\npars.β\n\n2.0\n\n\n\nタプルは()で囲まれた要素の集まりです.\nタプルの要素は[]を用いてアクセスできます.\n名前付きタプルは=を用いて要素に名前をつけることができます.\n名前付きタプルの要素は.を用いてアクセスできます.\n\n\nfunction tuple_sum(pars)\n    (; α, γ) = pars\n    return α + γ\nend\n\ntuple_sum(pars)\n\n5.0\n\n\n\n名前付きタプルの要素は(; )を用いて, 各要素に展開することができます\n\n\n\nベクトル, 行列 (Array)\n\n[1, 2, 3]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\n\n[1 2 3]\n\n1×3 Matrix{Int64}:\n 1  2  3\n\n\n\n[1; 2; 3]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\n\nベクトルは[]で囲まれた,区切りの要素の集まりです.\n空白区切りの場合は行列 (この場合は横ベクトル)として扱われます.\n; 区切りは行列の中での改行を表します. 結果的にこの場合は縦ベクトルとして扱われます.\n\n\n[1 2; 3 4]\n\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\n\n\nA = [1 2\n    3 4]\n\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\n\n\n行列は;区切りの行ベクトルを[]で囲むことで作成できます.\nなお;の代わりに改行を入れることもできます.\n\nレンジ\n\n0:0.1:1\n\n0.0:0.1:1.0\n\n\n\nstart:step:stop でレンジを作成できます.\nstart から stop まで step ずつ増加する数列を生成します.\nステップが省略された場合はデフォルトで1になります.\n\n\nrange(0, length=11, stop=1)\n\n0.0:0.1:1.0\n\n\n\nrange(start, length = n, stop = end) で n 個の start から end までの数列を生成できます.\n\n\n\n\n\n\n\nNoteレンジとベクトルの違い\n\n\n\nJuliaにおけるレンジはベクトルではなく, イテレータです. データとしては, レンジはベクトルではなく, レンジの始点, 終点, ステップの情報を持っているだけです. そのため, 生成の際のメモリは節約できる一方, ベクトルの様に要素を参照しようとすると計算コストがかかります.\n\nr = 0:0.1:1\ntypeof(r)\n\nStepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n\n\n\ntypeof(collect(r))\n\n\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\ncollect() 関数を用いることで, レンジをベクトルに変換することができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#特殊記法",
    "href": "lecture/10-1-julia-intro.html#特殊記法",
    "title": "Juliaの基礎",
    "section": "特殊記法",
    "text": "特殊記法\n\n内包表記\n\n[2^i for i in 1:5]\n\n5-element Vector{Int64}:\n  2\n  4\n  8\n 16\n 32\n\n\n\n[i + j for i in 1:3, j in 1:3]\n\n3×3 Matrix{Int64}:\n 2  3  4\n 3  4  5\n 4  5  6\n\n\n\n内包表記は[ ]の中でforループを用いてベクトルや行列を生成する方法です.\n1次元の場合はforループを1つ, 2次元の場合はforループを,で区切って2つ用います.\n\n\n\nドット記法\n\nf(x) = x^2\nf.([1, 2, 3])\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\n\n定数に対して定義された関数をベクトルや行列に適用する際には, .を関数名の後につけることで各要素に適用することができます.\n\n\n[1, 2, 3] .* [4, 5, 6]\n\n3-element Vector{Int64}:\n  4\n 10\n 18\n\n\n[1, 2, 3] * [4, 5, 6] # Error\n\n[1, 2, 3]' * [4, 5, 6]\n\n32\n\n\n\n.* は要素ごとの積を計算します.\n* は行列の積を計算します. この例では縦ベクトルと縦ベクトルの積は定義できないため, エラーが発生します.\n内積を計算する場合は, 'を用いて転置を行った後に行列の積を計算します."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#plots.jlの使い方",
    "href": "lecture/10-1-julia-intro.html#plots.jlの使い方",
    "title": "Juliaの基礎",
    "section": "Plots.jlの使い方",
    "text": "Plots.jlの使い方\n\nusing Plots\n\nPlots.jlは, Juliaで図を描画するためのパッケージです. そのバックエンドとして以下の様なパッケージを統一的な文法で扱うことができます.\n\nGR: デフォルト\nPlotly: JavaScriptを利用したインタラクティブなプロット\nPyPlot: Pythonのmatplotlibを利用\nPGFPlotsX: LaTeXのpgfplotsを利用\n\nこの授業では基本的にGRを使用します. また, Plots.jl以外のパッケージとして, 近年はMakieも人気を集めています.\n\n数列のプロット\n以下の様なフィボナッチ数列をプロットしてみましょう.\n\\[\nF_n = \\begin{cases}\n1 & n = 1, 2 \\\\\nF_{n-1} + F_{n-2} & n = 3, 4, \\dots\n\\end{cases}\n\\]\n\nN = 20\nfibs = zeros(Int, N)\nfibs[1], fibs[2] = 1, 1\nfor i = 3:N\n    fibs[i] = fibs[i-1] + fibs[i-2]\nend\n\nscatter(1:N, fibs, title=\"Fibonacci Sequences\", legends=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter: 散布図を描画します.\n\n\n\n関数のプロット\n\\[\nB_n = \\begin{cases}\n\\frac{1}{n} & n \\text{ odd} \\\\\n1 - \\frac{1}{n} & n \\text{ even}\n\\end{cases}\n\\]\n\nf(n) = isodd(n) ? 1 / n : 1 - 1 / n\nscatter(1:40, f, legends=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n描画関数 (e.g, scatter) の第2引数に関数を指定することで, 第一引数の値に対する関数の値をプロットできます\n\n\n\nプロットの重ね合わせ\n\nusing LaTeXStrings\n\nf₁(x) = x^2\nf₂(x) = x\nf₃(x) = log(x)\n\nxs = 0:0.01:1\nplot(xs, f₁, label=L\"f_1(x) = x^2\", legend=:bottomright)\nplot!(xs, f₂, label=L\"f_2(x) = x\")\nplot!(xs, f₃, label=L\"f_3(x) = \\log \\,x\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot: 折れ線グラフを描画します.\n!を付けることで, 既存のプロットに追加描画します.\nscatterを追加する場合は, scatter!を使用します.\n数式をグラフに表示するためには, LaTeXStringsパッケージを使用し, L\"...\"で囲みます.\n\n\n\nレイアウト\n\nf(x, y) = (x ≠ y) ? (x + y) / (x - y) : one(x)\nxs = range(-1.0, 1.0, length=100)\nys = copy(xs)\np1 = contour(xs, ys, f)\np2 = surface(xs, ys, f)\nplot(p1, p2, layout=(1, 2))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontour: 等高線プロットを描画します.\nlayout=(1, 2): レイアウトを指定します. この場合, 1行2列のプロットを描画します.\nより複雑なレイアウトはドキュメントを参照してください."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#julia-での表の作り方",
    "href": "lecture/10-1-julia-intro.html#julia-での表の作り方",
    "title": "Juliaの基礎",
    "section": "Julia での表の作り方",
    "text": "Julia での表の作り方\n\nusing SummaryTables\n\nレポートや論文を書く際に, Juliaのコードを実行した結果を表として出力したい場合, SummaryTables.jlを用いることができます. 最も簡単な方法は simple_table() 関数を用いることですが, より複雑な票を作成することも可能です. また, 出力形式としては, HTML, LaTeX, DOCX, Typst などがサポートされています.\n\ndata = (\n    id=1:5,\n    name=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n    age=[34, 29, 42, 37, 25],\n    score=[88, 92, 75, 80, 95]\n)\n\nsimple_table(data)\n\n\n\nTable 1: An example of SummaryTables.jl\n\n\n\n\n    \n    \n    \n        id\n        name\n        age\n        score\n    \n            \n        1\n        Alice\n        34\n        88\n    \n    \n        2\n        Bob\n        29\n        92\n    \n    \n        3\n        Charlie\n        42\n        75\n    \n    \n        4\n        David\n        37\n        80\n    \n    \n        5\n        Eve\n        25\n        95"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html",
    "href": "lecture/01-2-numerical-method.html",
    "title": "数値計算の基礎",
    "section": "",
    "text": "using Plots\nusing LaTeXStrings\nusing Roots\nusing NonlinearSolve\nusing FastGaussQuadrature\nusing Distributions\nusing SummaryTables\n\nimport Random\nRandom.seed!(1234)\ndefault(size=(500, 309), titlefontsize=10, fmt=:svg)"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#一階条件の数値解法",
    "href": "lecture/01-2-numerical-method.html#一階条件の数値解法",
    "title": "数値計算の基礎",
    "section": "一階条件の数値解法",
    "text": "一階条件の数値解法\nモデルを解くためには, 一階条件を解く必要があります. 特殊なケースや対数線形化などの場合を除き, 多くの場合の一階条件は非線形方程式となります. 非線形方程式の数値解法は, 一変数の場合と多変数の場合に分けられます.\n\n一変数の非線形方程式\nモデルを解く最初のステップとして, まずは意思決定者の最適化問題を解くことが挙げられます. 例えば以下の最適化問題を考えてみましょう.\n\\[\n\\max_{c, l} \\frac{c^{1-\\gamma_c}}{1-\\gamma_c} + \\alpha_l \\frac{l^{1-\\gamma_l}}{1-\\gamma_l} \\quad \\text{s.t.} \\quad c = w (1-l)\n\\tag{1}\\]\nこの問題は以下の一階条件の解を求めることで解くことができます.\n\\[\nw^{1-\\gamma_c} (1-l)^{-\\gamma_c} - \\alpha_l l^{\\gamma_l} = 0.\n\\]\n\nfoc(l; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5) =\n    w^(1 - γ_c) * (1 - l)^(-γ_c) - α_l * l^(-γ_l)\n\n\n\nCode\nplot(0.1:0.01:0.9, foc, label=L\"w^{1-\\gamma_c} (1-l)^{-\\gamma_c} - \\alpha_l l^{\\gamma_l}\", lw=2)\nhline!([0.0], ls=:dash, lw=2, label=false)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: FOC for CRRA utility\n\n\n\n\nこれは, 一般に解析解がありません (\\(\\gamma_c = \\gamma_l = 1\\)などを除く.) そのため, 数値計算を用いて解く必要があります. この様な一変数の非線形方程式 \\(f(x) = 0\\) の解法として, 以下の2つの選択肢があります.\n\nNon-bracketing method: 初期値 \\(x_0\\) からスタートして, \\(f(x_n)\\) が十分0に近づくまで反復的に計算. (ニュートン法など)\nBracketing method: 区間 \\([a, b]\\) を選び, 区間を狭めていくことで解を求める. (二分法など)\n\n一般に, Non-bracketing method は収束が速い代わりにその収束は保証されません. 一方で, Bracketing method は収束がわずかに遅い代わりに, 解が存在する区間を保証することができます. 以下では, その理由とそれぞれの適した利用場面を解説します.\n\nNon-bracketing method\nNon-bracketing method は基本的には一階微分を利用し, 初期値 \\(x_0\\) からスタートして反復的に解を求めます. ここでは, 最も古典的で簡単なニュートン法を紹介します.\n\n\n\n\n\n\nTipニュートン法\n\n\n\n\n初期値 \\(x_0\\) を選ぶ. また停止条件として十分小さい \\(\\epsilon &gt; 0\\) を選ぶ.\n\\(x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\\) を計算する.\n\\(|f(x_{n+1})| &lt; \\epsilon\\) ならば停止し, \\(x_{n+1}\\) を解として返す. そうでなければ, \\(n \\leftarrow n+1\\) として2に戻る.\n\n\n\n\n\n\n\n\n\nFigure 2: Visualization of Newton Method\n\n\n\n\ndfoc(l; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5) =\n    w^(1 - γ_c) * γ_c * (1 - l)^(-γ_c - 1) + α_l * γ_l * l^(-γ_l - 1)\n\nfind_zero((foc, dfoc), 0.5, Roots.Newton())\n\n0.530349570343484\n\n\nHybrid method\nJuliaのRoots.jlのデフォルトのNon-bracketing method (Order0())は, 厳密にはBracketing methodも一部利用します. また一階微分も必要としないため, より汎用的に利用することができます. ただし, 収束が速く収束が保証されない性質はNon-bracketing methodと同じです.\n\nl = find_zero(foc, 0.5)\n\n0.530349570343484\n\n\n定義域の変換\nNon-bracketing method では, \\(x_{n+1}\\) の値を更新する際に, 必ずしも \\(x_{n+1}\\) が定義域内にあることが保証されません. 例えば, 今回の例では 余暇時間であるため, \\(l \\in (0, 1)\\) ですが, 初期値や関数形によっては, \\(l &lt; 0\\) や \\(l &gt; 1\\) となる可能性があります.\nこの場合, 端点解が存在するかどうかを確認する必要があります. 端点解が想定される場合は, 次節で説明するように Bracketing method を利用することが適しています. 今回の例では, 端点解が存在しないため (\\(l = 0, 1\\) のどちらにおいても効用が負の無限大に発散するため), Non-bracketing method での解の収束が保証されています. 以下の様な定義域の変換を用いることで, 解の収束を保証することができます.\n\n\n\n\n\n\nNote定義域の変換\n\n\n\n\\(x\\) が区間 \\((a, b)\\) で定義されるとき, 以下の変換を用いて定義域を \\((-\\infty, \\infty)\\) にすることができる.\n\\[\nx = \\frac{a + b \\exp y}{1 + \\exp y}\n\\]\n明らかに, \\(y \\rightarrow -\\infty\\) のとき \\(x \\rightarrow a\\), \\(y \\rightarrow \\infty\\) のとき \\(x \\rightarrow b\\) となる.\n\n\n今回の例では, \\(l = \\frac{1}{1 + \\exp(y)}\\) (つまりシグモイド関数) という変換を用いることができます.\n\ny = find_zero(y -&gt; foc(1 / (1 + exp(y))), 0.0)\nl = 1 / (1 + exp(y))\n\n0.530349570343484\n\n\n\n\nBracketing method\nBracketing method は, 解が存在する区間 \\([a, b]\\) を選び, その区間を狭めていくことで解を求めます. ここでは最も基本的な二分法を用いることで解を求めることができます.\n\n\n\n\n\n\nTip二分法\n\n\n\n\n区間 \\([a, b]\\) を選ぶ. また停止条件として十分小さい \\(\\epsilon &gt; 0\\) を選ぶ.\n\\(f(a) \\cdot f(b) &lt; 0\\) ならば, \\(c = \\frac{a + b}{2}\\) を計算する.\n\\(|f(c)| &lt; \\epsilon\\) ならば, \\(c\\) を解として返す. そうでなければ, \\(f(a) \\cdot f(c) &lt; 0\\) ならば, \\(b \\leftarrow c\\) として2に戻る. そうでなければ, \\(a \\leftarrow c\\) として2に戻る.\n\n\n\n\n\n\n\n\n\nFigure 3: Visualization of Bisection Method\n\n\n\n例えば, 今回の例では \\(l \\in (0, 1)\\) であるため, \\(l = 0\\) と \\(l = 1\\) で効用が発散することから, 解が存在する区間は \\((0, 1)\\) です. なお, 端点でFOCが定義されてない場合も多いので, 端点より微小に内側の区間を選ぶことが多いです.\n\nϵ = 1e-9\nl = find_zero(foc, (ϵ, 1 - ϵ))\n\n0.530349570343484\n\n\n端点解の存在\n以下の様なカップルの意思決定問題を考えてみましょう.\n\\[\n\\max_{c_m, c_f, l_m, l_f} u(c_m, l_m) + u(c_f, l_f)\n\\]\nsubject to\n\\[\nc_m + c_f = w_m (1 - l_m) + w_f (1 - l_f).\n\\]\n一階条件から以下の関係が導けます:\n\\[\n\\frac{l_m}{l_f} = \\left(\\frac{w_f}{w_m}\\right)^{\\frac{1}{\\gamma_l}}.\n\\]\nこの関係から一方の相対賃金が十分に大きい場合, 例えば \\(w_m \\gg w_f\\) の場合, \\(l_f &gt; 1\\) となる可能性があります (\\(l_m\\) は余暇時間のため, 0よりある程度大きい値をとるということが想像できます.) 内点解が存在する場合の \\(l_f\\) に関する一階条件は以下のようになります.\n\\[\nw_m\\left(1-\\left(\\frac{w_f}{w_m}\\right)^{\\frac{1}{\\gamma_l}}l_f\\right) + w_f(1-l_f) - 2\\left(\\frac{w_f}{\\alpha_l}\\right)^{\\frac{1}{\\gamma_c}}l_f^{\\frac{\\gamma_l}{\\gamma_c}} = 0.\n\\]\n\n\nCode\nfunction foc_bargaining(l_f; w_m=1.0, w_f=0.5, γ_c=1.5, α_l=1.2, γ_l=1.5)\n    return w_m * (1 - (w_f / w_m)^(1 / γ_l) * l_f) + w_f * (1 - l_f) -\n           2 * (w_f / α_l)^(1 / γ_c) * l_f^(γ_l / γ_c)\nend\n\nlf_grid = 0.01:0.01:0.99\nplot(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=1.0), label=L\"w_f = 1.0\", xlabel=L\"l_f\")\nplot!(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=0.5), label=L\"w_f = 0.5\")\nplot!(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=0.1), label=L\"w_f = 0.1\")\nhline!([0.0], ls=:dash, lw=2, label=false, color=:black)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: FOC for bargaining problem. \\(w_m = 1.0\\), \\(\\alpha_l = 1.2\\), \\(\\gamma_c = \\gamma_l = 1.5\\).\n\n\n\n\nまた, \\(l_f = 1\\) における一階条件は以下のようになります.\n\\[\nw_m(1-l_m) - 2\\left(\\frac{w_m}{\\alpha_l}\\right)^{\\frac{1}{\\gamma_c}} l_m^{\\frac{\\gamma_l}{\\gamma_c}} = 0.\n\\]\nこの様な場合, Bracketing method の考えが有効です.\n\n端点 \\(l_m = 0, 1\\) (実用上は \\(\\epsilon, 1-\\epsilon\\)) において, 一階条件の値を計算.\n一階条件の値が異符号であれば, 二分法を用いて解を求める.\n一階条件の値が同符号であれば, 端点解 (この場合, \\(l_f = 1\\)) 上の解を求める.\n\n\nfunction solve_bargaining(; w_m=1.0, w_f=0.5, γ_c=1.5, α_l=1.2, γ_l=1.5)\n\n    ϵ = 1e-9\n    left = w_m * (1 - (w_f / w_m)^(1 / γ_l) * ϵ) + w_f * (1 - ϵ) -\n           2 * (w_f / α_l)^(1 / γ_c) * ϵ^(γ_l / γ_c)\n    right = w_m * (1 - (w_f / w_m)^(1 / γ_l) * (1 - ϵ)) + w_f * ϵ -\n            2 * (w_f / α_l)^(1 / γ_c) * (1 - ϵ)^(γ_l / γ_c)\n\n    if left * right &lt; 0\n        l_f = find_zero(\n            l_f -&gt; w_m * (1 - (w_f / w_m)^(1 / γ_l) * l_f) + w_f * (1 - l_f) -\n                   2 * (w_f / α_l)^(1 / γ_c) * l_f^(γ_l / γ_c),\n            (ϵ, 1 - ϵ))\n        l_m = (w_f / w_m)^(1 / γ_l) * l_f\n    else\n        l_f = 1.0\n        x = find_zero(\n            x -&gt; w_m * (1 - 1 / (1 + exp(x))) -\n                 2 * (w_m / α_l)^(1 / γ_c) * (1 / (1 + exp(x)))^(γ_l / γ_c),\n            0.0)\n        l_m = 1 / (1 + exp(x))\n    end\n\n    return l_m, l_f\nend\n\n\n\nCode\nplot(0.1:0.01:0.9, w_f -&gt; solve_bargaining(w_f=w_f)[1], label=L\"l_m\", xlabel=L\"w_f\")\nplot!(0.1:0.01:0.9, w_f -&gt; solve_bargaining(w_f=w_f)[2], label=L\"l_f\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Solution of bargaining problem. \\(w_m = 1.0, \\alpha_l = 1.2, \\gamma_c = \\gamma_l = 1.5\\).\n\n\n\n\n\n\n\n多変数の非線形方程式\n多変数の非線形方程式では Bracketing method は使えず, ニュートン法のような Non-bracketing method を用いる必要があります. そのため内点解と微分可能な関数を仮定しており, 端点解やスムースでない関数が想定される場合は使えません. そのような場合は, 原始的なグリッドサーチを用いるか, 後述するのように非線形最適化問題として解く必要があります.\nなお, 多くの標準的な効用関数 (CRRA, CESなど) の場合, 一階条件は一変数の非線形方程式に帰着できます. 今回は学習のために, 式 1 を3変数 (\\(c\\), \\(l\\), \\(\\lambda\\)) の非線形方程式として解いてみましょう.NonlinearSolve.jl を用いると便利です.\n\\[\n\\begin{aligned}\nc^{-\\gamma_c} &= \\lambda \\\\\n\\alpha_l l^{-\\gamma_l} &= \\lambda w \\\\\nc &= w(1-l)\n\\end{aligned}\n\\]\n\nfunction solve_nonlinear_system(; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5)\n    f((c, l, λ), par) = [\n        λ * c^γ_c - 1,\n        α_l - λ * w * l^γ_l,\n        c - w * (1 - l)\n    ]\n    prob = NonlinearProblem(f, [0.5, 0.5, 0.35], 0.)\n    sol = solve(prob, NewtonRaphson())\n\n    return (c=sol.u[1], l=sol.u[2], λ=sol.u[3])\nend\n\nsolve_nonlinear_system()\n\n(c = 0.469650429656516, l = 0.530349570343484, λ = 3.1069761107915044)\n\n\n工夫として負の指数を避けるように式変形しています. これは最適化の際に, 負の数の負の数乗によってエラーが起きることを避けるためです."
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#数値積分",
    "href": "lecture/01-2-numerical-method.html#数値積分",
    "title": "数値計算の基礎",
    "section": "数値積分",
    "text": "数値積分\n以下の定積分を \\(n\\) 個の区間に分割して近似的に計算することを考えます.\n\\[\n\\int_{a}^{b} f(x) \\,dx \\simeq \\sum_{i=1}^{n} w_i f(x_i)\n\\]\nここで, \\(w_i\\) は各区間の重み, \\(x_i\\) は各区間の評価点です. この形の積分計算はいくつか方法がありますが, 最も基本的な台形則と精度の高いガウス求積を紹介します.\n\n台形則 (Trapezoidal Rule)\n\n\n\n\n\n\nTip台形則 (Trapezoidal Rule)\n\n\n\n\n区間 \\([a, b]\\) を \\(n\\) 個の等間隔の区間に分割する. つまり, \\(x_i = a + i \\cdot \\frac{b - a}{n}\\) とする.\n各区間を台形で近似する. よって近似式は以下のようになる.\n\n\\[\n\\int_{a}^{b} f(x) \\,dx \\simeq \\sum_{i=1}^{n} (x_i - x_{i-1}) \\frac{f(x_{i-1}) + f(x_i)}{2}\n\\]\n\n\n\n\n\n\n\n\nFigure 6: Vizualization of Trapezoidal Rule\n\n\n\nここでは, \\(f(x) = \\sqrt{1 - x^2}\\) の \\([0, 1]\\) での積分を計算してみましょう. 単位円の1/4の面積であるため, 解析解は \\(\\pi / 4\\) です.\n\nfunction trapezoid_rule(f, a, b, n)\n    xs = range(a, b, length=n)\n    return sum((xs[i] - xs[i-1]) * (f(xs[i-1]) + f(xs[i])) / 2 for i in 2:n)\nend\n\nsol_tr100 = trapezoid_rule(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 100)\nsol_tr1000 = trapezoid_rule(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 1000)\n\nπ / 4, sol_tr100, sol_tr1000\n\n(0.7853981633974483, 0.7850997945286542, 0.7853888527655861)\n\n\n\n\nガウス求積 (Gaussian Quadrature)\n\n\n\n\n\n\nNoteガウス求積 (Gaussian Quadrature)\n\n\n\n\\(n\\) 次のルジャンドル多項式 \\(P_n(x)\\) の零点を \\(x_1, \\dots, x_n\\) とし, \\(L_i(x) = \\prod_{j \\neq i} (x - x_j)\\), \\(w_i = \\int_{-1}^{1} \\frac{L_i(x)}{L_i(x_i)} \\,dx\\) とすると,\n\\[\n\\int_{-1}^{1} f(x) \\,dx = \\sum_{i=1}^{n} w_i f(x_i)\n\\]\nが任意の \\(2n-1\\) 次の多項式 \\(f(x)\\) において成り立つ.\n\n\nこの方法は近似値ではなく, \\(2n-1\\) 次の多項式に対して厳密な値を計算することができるという点で強力です. また, \\(f(x)\\) が \\(2n-1\\) 次の多項式で十分近似できる場合, 精度の高い計算が可能です.\n\n\n\n\n\n\nTip定義域の変換 (ガウス求積)\n\n\n\nFastGaussQuadrature.jl 等のパッケージを利用する際には, 定義域を \\([-1, 1]\\) に変換する必要があります. \\(x = \\frac{b-a}{2} z + \\frac{a+b}{2}\\) と変換すると\n\\[\n\\int_{a}^b f(x) \\,dx = \\frac{b - a}{2} \\int_{-1}^1 f\\left(\\frac{b - a}{2} z + \\frac{a + b}{2}\\right) \\,dz\n\\]\nを得られます.\n\n\n\nfunction gaussian_quadrature(f, a, b, n)\n    z, w = gausslegendre(n)\n    return (b - a) / 2 * sum(w .* f.((b - a) / 2 * z .+ (a + b) / 2))\nend\n\nsol_gl10 = gaussian_quadrature(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 10)\nsol_gl100 = gaussian_quadrature(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 100)\n\nπ / 4, sol_gl10, sol_gl100\n\n(0.7853981633974483, 0.7855247925013235, 0.7853983068468604)\n\n\n10個程度の評価点で少数第三位まで, 100個程度の評価点で少数第六位までの精度が得られていることがわかります.\n\nガウスエルミート求積\nガウス求積は上にあげたガウス・ルジャンドル求積の他にも, ガウス・エルミート求積などの類似系があります.\n\n\n\n\n\n\nNoteガウス・エルミート求積 (Gaussian-Hermite Quadrature)\n\n\n\n\\(n\\) 次のエルミート多項式 \\(H_n(x)\\) の零点を \\(x_1, \\dots, x_n\\) とし, \\(w_i = \\frac{2^{n-1} n! \\sqrt{\\pi}}{\\left(n H_{n-1}(x_i)\\right)^2}\\) とすると,\n\\[\n\\int_{-\\infty}^{\\infty} f(x) e^{-x^2} \\,dx \\simeq \\sum_{i=1}^{n} w_i f(x_i)\n\\]\n\n\n被積分関数が \\(e^{-x^2}\\) という部分を持つ場合により高精度に計算することができます. 具体的には, 正規分布に基づく積分の計算などに利用可能です. ここで, 式 1 によって意思決定する人々の時間給 \\(w\\) が次のような分布に従っているとします.\n\\[\n\\log w \\sim \\mathcal{N}(\\mu, \\sigma).\n\\]\nこの時, 平均労働時間を積分によって求めてみましょう.\n\\[\n\\overline{h} = \\int_{0}^{\\infty} h^*(w) \\,dF(w; \\mu, \\sigma).\n\\]\nここで, \\(h^*(w)\\) は時給 \\(w\\) の下での最適労働時間, \\(F(w; \\mu, \\sigma)\\) は \\(w\\) の累積分布関数です. ここで \\(F(w; \\mu, \\sigma)\\) が対数正規分布であることを利用して, ガウス・エルミート求積を用いて計算します.\n\\[\n\\begin{aligned}\n\\overline{h} &= \\int_{-\\infty}^{\\infty} h^*(\\exp(y)) \\,d\\Phi(y; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} h^*(\\exp(y)) \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left(-\\frac{(y - \\mu)^2}{2\\sigma^2}\\right) \\,dy \\\\\n&=\\int_{-\\infty}^{\\infty} h^*\\left(\\exp\\left(\\sqrt{2}\\sigma z + \\mu\\right)\\right) \\frac{1}{\\sqrt{\\pi}} \\exp\\left(-z^2\\right) \\,dz \\\\\n&\\simeq \\sum_{i=1}^{n} w_i h^*\\left(\\exp\\left(\\sqrt{2}\\sigma x_i + \\mu\\right)\\right) \\frac{1}{\\sqrt{\\pi}}.\n\\end{aligned}\n\\]\nここでは \\(w = \\exp(y)\\), \\(y = \\sqrt{2}\\sigma z + \\mu\\) とした.\n\nfunction hours_worked(w; γ_c=1.5, α_l=1.2, γ_l=1.5)\n    y::Float64 = find_zero(y -&gt; foc(1 / (1 + exp(y)), w=w, γ_c=γ_c, α_l=α_l, γ_l=γ_l), 0.0)\n    l = 1 / (1 + exp(y))\n    return 1 - l\nend\n\nfunction mean_hours(; γ_c=1.5, α_l=1.2, γ_l=1.5, μ=0.0, σ=0.5, n=10)\n    x, w = gausshermite(n)\n    return sum(w .* hours_worked.(exp.(sqrt(2) * σ * x .+ μ), γ_c=γ_c, α_l=α_l, γ_l=γ_l) / sqrt(π))\nend\n\nmean_hours (generic function with 1 method)\n\n\n\n\n\nモンテカルロ法\n期待値を求める積分の場合, モンテカルロ法による近似も有効です. 速度は遅いですが, 実装が簡単であり, ガウス求積などたの方法による積分の検算などにも利用できます.\n\nmc_hours(; γ_c=1.5, α_l=1.2, γ_l=1.5, μ=0.0, σ=0.5, n=10^6) = mean(\n    hours_worked(rand(LogNormal(μ, σ)), γ_c=γ_c, α_l=α_l, γ_l=γ_l)\n    for _ in 1:n\n)\n\nmc_hours()\n\n0.46987292630609967"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#非線形最適化",
    "href": "lecture/01-2-numerical-method.html#非線形最適化",
    "title": "数値計算の基礎",
    "section": "非線形最適化",
    "text": "非線形最適化\n\n非線形最適化問題の解法\n\n非線形最適化問題\n非線形最適化問題は, 一般に以下のような形で表されます.\n\\[\n\\min_{\\mathbf{x} \\in \\mathbb{R}^n} f(\\mathbf{x}).\n\\]\nこの時, \\(f(\\mathbf{x})\\) を目的関数といいます. この時, \\(\\mathbf{x}\\) に制約条件がある場合があります.\n1. 境界制約 (Bound constraints, Box constraints)\n\\[\nlb_{i} \\le x_{i} \\le ub_{i}, \\quad i = 1, \\dots, n.\n\\]\n2. 不等式制約 (Inequality constraints)\n\\[\nc_i(x_i) \\le 0, \\quad i = 1, \\dots, n.\n\\]\n3. 等式制約 (Equality constraints)\n\\[\nh_i(x_i) = 0, \\quad i = 1, \\dots, n.\n\\]\n制約付き最適化問題を扱えるかどうか, どの種類の制約まで扱えるかはアルゴリズムによって異なります.\n\n\n最適化アルゴリズム\n最適化アルゴリズムは日々進化しており, 様々なアルゴリズムが提案されています. どのアルゴリズムを用いるべきかは, 一般に判断が難しく, いくつかのアルゴリズムを実際に試してみる必要があります. ここでは, アルゴリズムを選ぶ際の概ねの考え方を紹介します. 詳細な解説は, 後に紹介する Nlopt パッケージのドキュメント を参照にしてください.\nGlobal vs. Local Method\n基本的に非線形最適化の数値計算では局所解しか求められません (\\(\\mathbb{R}^n\\) の全体を探索することはできないため). しかし, 数値計算の文脈では以下の意味で Global Method と Local Method に分けることができます.\n\nGlobal Method: Box constraints の中で満遍なく探索した場合, 最適である\nLocal Method: 初期値からの探索の結果, 最適である\n\nこの意味で, NLopt では GN_DIRECT や GN_ISRES などのいくつかのアルゴリズムが Global Method に分類されます. しかし, これらのアルゴリズムは計算時間が長く, 特に次元数の多い場合は計算が (現実的な研究時間の範囲で) 終了しない場合があります. そのため, これらの Global Method を用いる場合は, 評価回数や評価時間を制限してある程度の精度で計算を終了する必要があります. また, ここで求められた値を初期値として Local Method を用いることでより精度の高い解を求めることができます.\nGradient-based vs. Derivative-free Method\n最適化アルゴリズムは, 一階微分を用いるものと用いないものに分けることができます. 一階微分が事前に分かっている場合, 自動微分などで計算できる場合は, 一階微分を用いる方が計算が速く, 精度も高いです. これまで見てきたニュートン法などもこれに該当します. しかし, 複雑な問題では一階微分を計算することが困難な場合があります. その場合, Derivative-free なアルゴリズムを用いる必要があります.\nJuliaのパッケージ\nJuliaでよく使われる Optim.jl というパッケージでは, Gradient-based な local method として BFGS (ニュートン法の一種) がよく用いられており, Derivative-free な local method として Nelder-Mead がよく用いられています. さらに複雑なアルゴリズムを扱う場合は, NLopt.jl というパッケージを用いることが多いです. 数多くの最適化手法が Global, Local, Gradient-based, Derivative-free 満遍なく実装されており, それぞれのアルゴリズムを選ぶことができます. また, NLopt 自体はC++, Python, Rなどでも利用可能なライブラリです.\n私は簡単な最適化の場合は Optim.jl を用い, 複雑な最適化 (特に後述するSMM) の場合は NLopt.jl を用いることが多いです.\n\n\nOptimization.jl\nOptimization.jl は, 多くの最適化パッケージを統一的に扱うために作成されたパッケージです. すでに紹介した Optim.jl や NLopt.jl などのパッケージを同じ文法で扱うことができるため, 様々な最適化アルゴリズムを試す際に便利です.\n今回は, NLopt.jl と Optim.jl の両方を用いて, Rosenbrock 関数の最適化を行ってみます.\n\n\n\n\n\n\nNoteRosenbrock 関数\n\n\n\n\\(\\mathbf{x} = (x_1, \\dots, x_n)' \\in \\mathbb{R}^n\\) に対して,\n\\[\nf(x_1, \\dots, x_n) = \\sum_{i=1}^{n-1} \\left(100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\\right).\n\\]\n\n\nRosenbrock 関数は, 凸性がないため, 最適化アルゴリズムの性能を比較するために用いられることが多いです. また, 解として \\(f(1, \\dots, 1) = 0\\) が知られています. 2変数の場合, 以下のような形になります.\n\nrosenbrock(x, y) = (1 - x)^2 + 100 * (y - x^2)^2\nx_grid = -2:0.01:2\ny_grid = -1:0.01:3\n\np1 = contour(x_grid, y_grid, (x, y) -&gt; log1p(rosenbrock(x, y)), xlabel=L\"x\", ylabel=L\"y\", label=false)\np2 = surface(x_grid, y_grid, (x, y) -&gt; log1p(rosenbrock(x, y)), xlabel=L\"x\", ylabel=L\"y\", label=false)\n\nplot(p1, p2, layout=(1, 2), size=(800, 400))\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Rosenbrock function. Z-axis is log plus one of Rosenbrock function.\n\n\n\n\nこれをOptimization.jlを用いて解いてみましょう. まずは, Optim.jl のNelder-Mead法を用いて解いてみます.\n\nusing Optimization\nusing OptimizationOptimJL\n\nprob = OptimizationProblem((x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.])\nsol = solve(prob, NelderMead())\n\nretcode: Success\nu: 2-element Vector{Float64}:\n 0.9999634355313174\n 0.9999315506115275\n\n\nOptimization.jl のやや癖のあるところは, \\(f(\\mathbf{x}, \\mathbf{p})\\) のように, パラメータ \\(\\mathbf{p}\\) を必ず与える必要があるところです. そのため, 匿名関数を用いて, \\(f(\\mathbf{x}, \\mathbf{p})\\) 型に変換しています.\n次に, NLopt.jl を用いて解いてみます. 今回は, local method の COBYLA (LN_COBYLA) を用いて解いてみます. これも, derivative-free なアルゴリズムです.\n\nusing OptimizationNLopt\n\nprob = OptimizationProblem((x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.])\nsol = solve(prob, NLopt.LN_COBYLA())\n\nretcode: Success\nu: 2-element Vector{Float64}:\n 0.9999999999996291\n 0.9999999999992569\n\n\n次に, NLopt.jl の global method の GN_DIRECT を用いて解いてみます. こちらは, 探索範囲を制限し, 評価回数を制限して計算を終了します.\n\nprob = OptimizationProblem(\n    (x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.], lb=[-2, -2], ub=[2, 3])\nsol = solve(prob, NLopt.GN_DIRECT(), maxiters=10000)\n\nretcode: MaxIters\nu: 2-element Vector{Float64}:\n 0.9999999999971578\n 0.9999999999943192\n\n\n\n\n\nSimulated Method of Moments (SMM)\nモデルのパラメータの決定方法には以下の3つの方法があります.\n\n先行研究のパラメータを用いる (\\(\\beta = 0.96\\), Prescott (1986) など)\nデータから回帰分析などを用いて直接推定する.\nモデルのシミュレーション結果とデータを比較し, それに合うようにパラメータを調整する (Simulated Method of Moments, SMM)\n\n2の方法は, モデルごとに設定した関数形の一階条件などから導かれる式にデータを代入することでパラメータを推定する方法です. モデルごとに工夫がなされているため, 今後の授業でモデルを学ぶ際に紹介します. また1の方法で用いられるパラメータも先行研究において, 2の方法で推定された値を用いていることが多いです.\nこの節では, 3の方法であるSMMの概略を紹介します. 今後の授業で扱うモデルでももほとんど共通の方法が用いられています.\n\n\n\n\n\n\nNoteSimulated Method of Moments (SMM)\n\n\n\n\\(n\\) 次元のパラメータ \\(\\theta\\) を推定するとする. \\(\\theta\\) を代入した際にモデル (のシミュレーション) によって得られる \\(m \\ge n\\) 次元のモーメントを \\(\\mathcal{M}(\\theta)\\) とする. また, データから得られる同様のモーメントを \\(\\text{Data}\\) とする. 任意の対称重み行列 \\(W\\) を用いて, 以下の最適化問題を解く.\n\\[\n\\hat{\\theta} = \\arg\\min_{\\theta} \\left(\\mathcal{M}(\\theta) - \\text{Data}\\right)' W \\left(\\mathcal{M}(\\theta) - \\text{Data}\\right)\n\\]\n\n\nここで, 重み行列 \\(W\\) は, 単位行列, \\(\\text{diag}(\\text{Data})\\), \\(\\text{diag}(\\mathbb{V}(\\text{Data}))\\) を用いることが多いです. また推定値に対する標準誤差も計算すべきですが, 分散共分散行列の計算が必ずしも計算できない場合があるなど, かなり複雑な問題があります. 詳細は Cocci and Plagborg-Møller (2024) の議論を参照してください. 実際の論文では標準誤差を示さない場合も多いです.\n\nSMMの実践\nここでは, SMMを用いて労働供給のパラメータを推定する. かなり簡略化された例を用いるため, モデルの当てはまりは悪いが, SMMの考え方を理解するための例として利用する.\nモデル\n\\[\n\\max_{c, l} u(c, l) = \\log c + \\alpha \\log (1-l) \\quad \\text{s.t.} \\quad c = w (1 - l)\n\\]\n\n\\(c\\): 消費\n\\(w\\): 時給\n\\(l\\): 余暇時間\n\n時給 \\(w\\) は以下のような分布に従うとする.\n\\[\n\\log w \\sim \\mathcal{N}(\\mu, \\sigma).\n\\]\n標準化のため, \\(\\mu = 0\\) とする. この時, \\(\\theta = (\\alpha, \\sigma)\\) を推定する.\nデータ\nリクルートワークス研究所の 全国就業実態パネル調査 を用いる. なお, JPSED.stat から集計データをダウンロードすることができる. ここでは, 最新の2023年の20-29歳男性のデータを用いる.\n\n労働時間分布: 週あたりの労働時間 33.4時間\n\n週あたりの利用可能な労働時間は, \\(16 \\times 7 = 112\\) 時間とし, \\(1 - \\bar{l} = 1 - 33.4 / 112 \\simeq 0.7\\)\n\n所得分布: 主な仕事からの年収. 図 8.\n\n50万円未満は25万円, 50-100万円は75万円のように間の値を用い, 1200万円以上は1200万円とする\n対数所得の分散をターゲットとする\n\n\n\nmean_leisure_data = 1 - 33.4 / (16 * 7)\nearn = [25, 75, 150, 250, 350, 450, 550, 650, 750, 850, 950, 1100, 1200]\ndensity = [13.7, 12.2, 12.3, 14.8, 20.2, 16.3, 7.0, 2.0, 0.6, 0.4, 0.1, 0.3, 0.2] / 100\nmean_learn_data = density' * log.(earn)\nsd_learn_data = sqrt(density' * (log.(earn) .- mean_learn_data) .^ 2)\n\nplot(earn, density, label=\"Density\", xlabel=\"Earnings (10K JPY)\",\n    ylabel=\"Density\", lw=2, legend=false)\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Distribution of earnings. Data from JPSED.stat. 20-29 aged men in 2023.\n\n\n\n\n一階条件から容易に \\(l = \\frac{\\alpha}{w + \\alpha}\\) となることがわかります. ガウス・エルミート求積を用いて, 労働時間の平均は以下のように計算できます.\n\\[\n\\begin{aligned}\n\\mathbb{E}[l] &= \\int_{-\\infty}^{\\infty} l(w) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\frac{\\alpha}{w + \\alpha} \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq \\sum_{i=1}^{n} \\xi_i \\frac{\\alpha}{\\exp\\left(\\sqrt{2}\\sigma x_i + \\mu\\right) + \\alpha} \\frac{1}{\\sqrt{\\pi}} \\\\\n\\end{aligned}\n\\]\nここで, \\(\\xi_i, x_i\\) はガウス・エルミート求積の重みと評価点です. 同様に, 対数収入 \\(\\log e\\) の平均と分散は以下のように計算できます.\n\\[\n\\begin{aligned}\n\\mathbb{E}[\\log e] &= \\int_{-\\infty}^{\\infty} \\log(w(1-l)) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\log\\left(\\frac{w^2}{\\alpha + w}\\right) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} 2\\log w \\,dF(w; \\mu, \\sigma) - \\int_{-\\infty}^{\\infty} \\log (\\alpha + w) \\,dF(w; \\mu, \\sigma) \\\\\n&= 2\\mu - \\int_{-\\infty}^{\\infty} \\log (\\alpha + w) \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq 2\\mu - \\sum_{i} \\xi_i \\log\\left(\\alpha + \\exp(\\sqrt{2}\\sigma x_i + \\mu)\\right)\\frac{1}{\\sqrt{\\pi}}\\\\\n\\text{Var}(\\log e) &= \\int_{-\\infty}^{\\infty} \\left(\\log(w(1-l)) - \\overline{\\log e}\\right)^2 \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\left(2\\log w - \\log(\\alpha + w) - \\overline{\\log e}\\right)^2 \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq \\sum_{i}^{n} \\xi_i \\left(2(\\sqrt{2}\\sigma x_i + \\mu) - \\log\\left(\\alpha + \\exp(\\sqrt{2}\\sigma x_i + \\mu)\\right) - \\overline{\\log e}\\right)^2 \\frac{1}{\\sqrt{\\pi}}\\\\\n\\end{aligned}\n\\]\n\nfunction moment(α, σ; n_gh=10)\n    x, ξ = gausshermite(n_gh)\n    μ = 0.0\n    mean_leisure = ξ' * (α ./ (exp.(sqrt(2) * σ * x .+ μ) .+ α)) / sqrt(π)\n    mean_learn = 2μ - ξ' * log.(α .+ exp.(sqrt(2) * σ .* x .+ μ)) / sqrt(π)\n    sd_learn = sqrt(ξ' * (2 * (sqrt(2) * σ .* x .+ μ) - log.(α .+ exp.(sqrt(2) * σ .* x .+ μ)) .- mean_learn) .^ 2 / sqrt(π))\n\n    return [mean_leisure, sd_learn]\nend\n\nloss(α, σ; d=[mean_leisure_data, sd_learn_data]) = sqrt(sum(((moment(α, σ) .- d) ./ d) .^ 2))\nprob = OptimizationProblem((x, p) -&gt; loss(x[1], x[2]), [0.5, 0.5])\nsol = solve(prob, NelderMead()) # Optim.jl\nα, σ = sol.x\n\n2-element Vector{Float64}:\n 2.5167745032341324\n 0.5961675492466839\n\n\nなお, ほとんどの場合は3変数以上の最適化問題を解くため確認することができませんが, 2変数の場合はプロットにより損失関数の形状を確認することができます.\n\ncontour(0.01:0.01:5, 0.01:0.01:1, loss)\nscatter!([α], [σ], label=\"Solution\", markersize=5)\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Contour plot of loss function.\n\n\n\n\nおそらく唯一の (局所) 解であることがわかります.\n\n\nCode\nmnt = moment(α, σ)\n\ndata = (\n    Parameter=[\"α\", \"σ\"],\n    Value=[α, σ],\n    Target=[\"Mean of Leisure Hours\", \"S.D. of Log Earnings\"],\n    Data=[mean_leisure_data, sd_learn_data],\n    Model=mnt\n)\n\nsimple_table(data)\n\n\n\n\nTable 1: Results of SMM\n\n\n\n\n    \n    \n    \n        Parameter\n        Value\n        Target\n        Data\n        Model\n    \n            \n        α\n        2.52\n        Mean of Leisure Hours\n        0.702\n        0.702\n    \n    \n        σ\n        0.596\n        S.D. of Log Earnings\n        1.02\n        1.02\n    \n    \n\n\n\n\n\n\n表 1 の結果から, モデルから得られたモーメントがデータのモーメントとほとんど一致していることがわかります. このモデルの当てはまりを確認するためにターゲットとしていないモーメントとして, 労働時間の分布を確認してみましょう. 推定された \\(\\alpha, \\sigma\\) の値を用いてモンテカルロシミュレーションを行い, 労働時間の分布を確認します. なお, 労働時間は \\(h^*(w) = 1 - \\frac{\\alpha}{w + \\alpha}\\) で計算でき, 週あたりの労働時間に直すために \\(h^*(w) \\times 16 \\times 7\\) を計算します.\n\nlbl_hours = [\"0-19\", \"20-34\", \"35-44\", \"45-59\", \"60+\"]\ndens_hours_data = [22.4, 12.1, 44.7, 17.9, 3.8] / 100\nhours_model = [(w / (w + α)) * 16 * 7 for w in rand(LogNormal(0, σ), 10^6)]\n\nbins = [0, 20, 35, 45, 60, 113]\ndens_hours_model = [mean(bins[i] .&lt;= hours_model .&lt; bins[i+1]) for i in 1:(length(bins)-1)]\n\nbar(lbl_hours, dens_hours_data, label=\"Model\")\nscatter!(lbl_hours, dens_hours_model, label=\"Data\", xlabel=\"Hours Worked per Week\")\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Distribution of hours worked.\n\n\n\n\n図 10 で分かるように, モデルの労働時間の分布はデータの労働時間の分布とかなり異なります. これは, モデルが単純化されすぎているためです. 例えば, 20-29歳の男性のデータを用いてるため, 学生や新卒の人々が多く含まれており, 労働時間が短くなっている可能性があります. また, 賃金に対する労働時間の弾力性 (フリッシュ弾力性) が重要な役割を果たしていると考えられるにもかかわらず, 対数型効用関数という柔軟性のない効用関数を用いていることに問題がある可能性があります. ターゲットとしたモーメントの当てはまりは定義から良いので, ターゲットとしていないモーメントによる評価も重要です."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "",
    "text": "Kazuharu Yanagimoto\n        \n        \n            Macro IV・Fall 2025Kobe University"
  },
  {
    "objectID": "index.html#スケジュール",
    "href": "index.html#スケジュール",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "スケジュール",
    "text": "スケジュール\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                \n                タイトル\n                教材\n                課題提出\n              \n        \n        \n        \n                \n                  基礎編\n                  基礎編\n                  基礎編\n                  基礎編\n                \n                \n                  2025-10-06\n                  Introduction\n                  \n                   \n                \n                \n                  2025-10-15\n                  数値計算の基礎\n                  \n                   \n                \n                \n                  2025-10-20\n                  動学モデルの基礎\n                  \n                  2025-10-28\n                \n                \n                  結婚の経済学\n                  結婚の経済学\n                  結婚の経済学\n                  結婚の経済学\n                \n                \n                  2025-10-27\n                  Search and Matching I\n                  \n                   \n                \n                \n                  2025-11-06\n                  Search and Matching II\n                  \n                   \n                \n                \n                  2025-11-10\n                  Frictionless Marriage Market I\n                  \n                   \n                \n                \n                  2025-11-17\n                  Frictionless Marriage Market II\n                  \n                  2025-12-02\n                \n                \n                  出生の経済学\n                  出生の経済学\n                  出生の経済学\n                  出生の経済学\n                \n                \n                  2025-12-01\n                  Old Facts, Old Models\n                  \n                   \n                \n                \n                  2025-12-08\n                  Kuznet's Facts for Family Economists\n                  \n                   \n                \n                \n                  2025-12-15\n                  New Theory of Fertility I\n                  \n                   \n                \n                \n                  2025-12-22\n                  New Theory of Fertility II\n                  \n                   \n                \n                \n                  ジェンダー格差\n                  ジェンダー格差\n                  ジェンダー格差\n                  ジェンダー格差\n                \n                \n                  2026-01-05\n                  Non-linear Wage\n                  \n                   \n                \n                \n                  2026-01-14\n                  Home Production\n                  \n                   \n                \n                \n                  2026-01-19\n                  Intra-household Allocation\n                  \n                  2025-01-29\n                \n                \n                  まとめ\n                  まとめ\n                  まとめ\n                  まとめ\n                \n                \n                  2026-01-26\n                  まとめ\n                  \n                   \n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\nTipSubscribe!\n\n\n\n授業スケジュールをGoogle Calendarなどに登録できます. 私個人のために作成したものであり間違いがある可能性があります. 大学からの正式なスケジュールを優先した上で, 参考程度にご利用ください."
  },
  {
    "objectID": "index.html#課題について",
    "href": "index.html#課題について",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "課題について",
    "text": "課題について\n提出期限\n\n対応するTAセッションの前日23:59 (JST)\n例: 10月29日のTAセッション → 10月28日23:59まで\n\n提出方法\n\nGoogle Classroom上でPDFレポートとコードをアップロード\nTAのPC上で動作確認を行う. 再現できない場合は, TAが環境について質問することがある\n\nコードについて\n\nTAのPC上で動作確認を行うため, 無料で利用できる言語 (Julia, Python, R等) を利用すること\n授業ではコード例としてJuliaを利用するため, Juliaを利用することを推奨\n第1回TAセッションでJuliaの基本的な使い方を解説する\n\nレポートについて\n\nPDF形式で提出. タイプされたもののみ. 手書きは不可\n\nレポートにコードは含めないこと\n図と表以外のコード実行のアウトプットも含めてはいけない\nTAのPC上でコンパイルすることから, Quartoでは有料のフォント (特にMacのヒラギノ) は利用しないこと.\n\nQuarto での作成を推奨する. \\(\\LaTeX\\) 等でレポートを作成した場合は, レポート用のコードの提出は必要ない\n\nQuarto (Julia) の場合 → PDFレポートとqmdファイルの提出\nPython + \\(\\LaTeX\\) の場合 → PDFレポートとpyファイルの提出\n\nQuartoを用いない場合は main 関数を定義し, TAが main 関数を実行することのみでレポートで用いる画像や数値が再現できるようにすること\n第1回のTAセッションでQuartoの基本的な使い方を解説する\n解答には以下のテンプレートを利用してもよい\n\n Template   Exercise 0"
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture Materials",
    "section": "",
    "text": "2025年10月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月20日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood and Guner (2009)\n\n\n\n\n\n2025年10月27日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood et al. (2016)\n\n\n\n\n\n2025年11月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGayle and Shephard (2019)\n\n\n\n\n\n2025年11月10日\n\n\n\n\n\n\n\n\n\n\n\n\n\nReynoso (2024)\n\n\n\n\n\n2025年11月17日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoepke et al. (2023)\n\n\n\n\n\n2025年12月1日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood, Guner, and Marto (2023)\n\n\n\n\n\n2025年12月8日\n\n\n\n\n\n\n\n\n\n\n\n\n\nKim, Tertilt, and Yum (2024)\n\n\n\n\n\n2025年12月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdda, Dustmann, and Stevens (2017)\n\n\n\n\n\n2025年12月22日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErosa et al. (2022)\n\n\n\n\n\n2026年1月5日\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalvo, Lindenlaub, and Reynoso (2024)\n\n\n\n\n\n2026年1月14日\n\n\n\n\n\n\n\n\n\n\n\n\n\nLise and Yamada (2019)\n\n\n\n\n\n2026年1月19日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture.html#講義資料",
    "href": "lecture.html#講義資料",
    "title": "Lecture Materials",
    "section": "",
    "text": "2025年10月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月20日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood and Guner (2009)\n\n\n\n\n\n2025年10月27日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood et al. (2016)\n\n\n\n\n\n2025年11月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGayle and Shephard (2019)\n\n\n\n\n\n2025年11月10日\n\n\n\n\n\n\n\n\n\n\n\n\n\nReynoso (2024)\n\n\n\n\n\n2025年11月17日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoepke et al. (2023)\n\n\n\n\n\n2025年12月1日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood, Guner, and Marto (2023)\n\n\n\n\n\n2025年12月8日\n\n\n\n\n\n\n\n\n\n\n\n\n\nKim, Tertilt, and Yum (2024)\n\n\n\n\n\n2025年12月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdda, Dustmann, and Stevens (2017)\n\n\n\n\n\n2025年12月22日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErosa et al. (2022)\n\n\n\n\n\n2026年1月5日\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalvo, Lindenlaub, and Reynoso (2024)\n\n\n\n\n\n2026年1月14日\n\n\n\n\n\n\n\n\n\n\n\n\n\nLise and Yamada (2019)\n\n\n\n\n\n2026年1月19日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture.html#appendix",
    "href": "lecture.html#appendix",
    "title": "Lecture Materials",
    "section": "Appendix",
    "text": "Appendix\n\n\n\n\n\n\n\n\n\n\nJuliaの基礎\n\n\n\n\n\n\n\n\n2025年10月1日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html",
    "href": "lecture/01-3-dynamic-model.html",
    "title": "動学モデルの基礎",
    "section": "",
    "text": "using Plots\nusing LaTeXStrings\nusing Distributions\nimport Random\nusing Roots\nusing LinearAlgebra\nusing Interpolations\ndefault(size=(500, 309), titlefontsize=10, fmt=:svg)"
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#ベルマン方程式の数値解法",
    "href": "lecture/01-3-dynamic-model.html#ベルマン方程式の数値解法",
    "title": "動学モデルの基礎",
    "section": "ベルマン方程式の数値解法",
    "text": "ベルマン方程式の数値解法\n以下の無限期間代表的個人のモデルを考えます.\n\\[\n\\max_{\\{c_t, k_{t+1}\\}_{t=0}^{\\infty}} \\sum_{t=0}^{\\infty} \\beta^t u(c_t) \\quad \\text{s.t.} \\quad c_t + k_{t+1} = f(k_t) + (1-\\delta)k_t.\n\\]\nこれをベルマン方程式 \\(V(k)\\) に書き換えた時の数値解法を考えます.\n\\[\nV(k) = \\max_{k'} \\left\\{u(f(k) + (1-\\delta)k - k') + \\beta V(k')\\right\\}\n\\]\n大きく分けて, 2つの方法があります.\n\nValue Function Iteration\n\nベルマン方程式の不動点を直接求める方法\n収束性が保証されているが, 収束速度は比較的遅い\n\nPolicy Function Iteration\n\nオイラー方程式の不動点を求める方法\n収束性は保証されていないが, 収束速度は比較的速い\n\n\n数値計算に用いるために, 以下の関数形とパラメータを仮定します.\n\n\\(u(c) = \\log c\\)\n\\(f(k) = k^\\alpha\\)\n\\(\\beta = 0.96\\)\n\\(\\delta = 0.1\\)\n\\(\\alpha = 0.36\\)\n\n\n@kwdef struct Model{TF&lt;:AbstractFloat,TI&lt;:Integer}\n    # Parameters\n    α::TF = 0.4\n    β::TF = 0.96\n    δ::TF = 0.1\n\n    # Value Function\n    n_k::TI = 101\n    k_min::TF = 0.05\n    k_max::TF = 0.5\n    k_grid::Vector{TF} = collect(range(k_min, k_max, length=n_k))\n    V::Vector{TF} = zeros(n_k)\n    h::Vector{TF} = copy(k_grid)\nend\n\nu(c; m) = log(c)\nu′(c; m) = 1 / c\nf(k; m) = k^m.α\nf′(k; m) = m.α * k^(m.α - 1)\n\n\nValue Function Iteration\n\n\n\n\n\n\nNoteValue Function Iteration\n\n\n\n\n\\(k\\) の定義域を \\([k_{\\min}, k_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する.\n\\(V(k)\\) の初期値 \\(V^0\\) を適当に設定する. つまり, \\(V^0 = (V_0^0, V_1^0, \\dots, V_n^0)\\) に適当な値を設定する.\n\\(V^0\\) をベルマン方程式の右辺に代入し, 各 \\(k_i\\) に対して \\(V_i^1\\) を計算する.\n\n\\(h(f(k) + (1-\\delta)k - c)\\) は補完によって計算する\n線形補完, スプライン補完などを用いる\n\n2-3を繰り返す. 収束条件は以下のように設定する.\n\n\\(|V^N - V^{N-1}| &lt; \\varepsilon\\)\n\\(|V^N - V^{N-1}|\\) はベクトルのノルム\n\\(\\varepsilon\\) は十分小さな値を設定する. 例えば, \\(\\epsilon = 10^{-6}\\) とする\n\n\n\n\nなおこのような収束の閾値 \\(\\varepsilon\\) を tolerance と呼ぶことがあります.\n\nfunction vfi!(m::Model; tol=1e-6, max_iter=1000, verbose=true)\n    (; k_grid, β, δ) = m\n\n    iter, dist = 0, Inf\n    V_new = similar(m.V)\n    while dist &gt; tol && iter &lt; max_iter\n        for (i_k, k) in enumerate(k_grid)\n            c_min = 1e-9 # consumption cannot be negative\n            V_new[i_k] = maximum(\n                log(max(f(k; m) + (1 - δ) * k - k′, c_min)) + β * m.V[i_k′]\n                for (i_k′, k′) in enumerate(k_grid)\n            )\n        end\n\n        dist = maximum(abs, V_new - m.V)\n        m.V .= V_new\n        iter += 1\n    end\n\n    if verbose\n        if iter == max_iter\n            println(\"Warning: Maximum iterations reached.\")\n        else\n            println(\"Converged in $iter iterations.\")\n        end\n    end\n\n    return nothing\nend\n\n\nm = Model()\nvfi!(m)\nplot(m.k_grid, m.V, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k)$\")\n\nConverged in 315 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Value Function Iteration\n\n\n\n\nなお, 各イタレーションでは, \\(k\\) に対する最適な \\(k'\\) や \\(c\\) を求めています. それらを記録しておくことで, 政策関数 \\(c = h(k)\\) や \\(k' = g(k)\\) を求めることができます.\n\n\nPolicy Function Iteration\n上記のベルマン方程式から, 以下のオイラー方程式が導出されます.\n\\[\nu'(c) = \\beta u'(c')\\left(f'(k') + (1-\\delta)\\right).\n\\]\nここで, 政策関数 \\(c' = h(k')\\) と予算制約 \\(k' = f(k) + (1-\\delta)k - c\\) を導入すると, 上記のオイラー方程式は以下のように書き換えられます.\n\\[\nu'(c) = \\beta u'(h(f(k) + (1-\\delta)k - c))\\left(f'(f(k) + (1-\\delta)k - c) + (1-\\delta)\\right).\n\\]\nこの時, \\(h(k)\\) を所与とした時に \\(c\\) について解くと新しい政策関数 \\(h(k)\\) が得られます. この政策関数繰り返し更新することで, 政策関数の不動点を求めることができます.\n\n\n\n\n\n\nNotePolicy Function Iteration\n\n\n\n\n\\(k\\) の定義域を \\([k_{\\min}, k_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する\n\\(h(k)\\) の初期値 \\(h^0\\) を適当に設定する. つまり, \\(h^0 = (h_0^0, h_1^0, \\dots, h_n^0)\\) に適当な値を設定する.\n\\(h^0\\) をオイラー方程式の右辺に代入し, 各 \\(k_i\\) に対して \\(h_i^1\\) を計算する.\n2-3を繰り返す. 収束条件は以下のように設定する.\n\n\\(|h^N - h^{N-1}| &lt; \\varepsilon\\)\n\\(|h^N - h^{N-1}|\\) はベクトルのノルム\n\\(\\varepsilon\\) は十分小さな値を設定する. 例えば, \\(\\epsilon = 10^{-6}\\) とする\n\n\n\n\n\nfunction euler_eq(c, k, h; m)\n    (; β, δ, k_grid) = m\n\n    k′ = max(f(k; m) + (1 - δ) * k - c, k_grid[begin])\n    h_interp = linear_interpolation(k_grid, h)\n    c′ = h_interp(k′)\n\n    return u′(c; m) - β * u′(c′; m) * (f′(k′; m) + 1 - δ)\nend\n\nfunction pfi!(m::Model; tol=1e-6, max_iter=1000, verbose=true)\n    (; k_min, k_max, k_grid, α, β, δ) = m\n\n    h_new = similar(m.h)\n    iter, dist = 0, Inf\n    while dist &gt; tol && iter &lt; max_iter\n\n        for (i_k, k) in enumerate(k_grid)\n            c_min = max(1e-9, f(k; m) + (1 - δ) * k - k_grid[end])\n            c_max = f(k; m) + (1 - δ) * k - k_grid[begin]\n            ee_left = euler_eq(c_min, k, m.h; m)\n            ee_right = euler_eq(c_max, k, m.h; m)\n            if ee_left &gt; 0 && ee_right &gt; 0\n                h_new[i_k] = c_max\n            elseif ee_left &lt; 0 && ee_right &lt; 0\n                h_new[i_k] = c_min\n            else\n                h_new[i_k] = find_zero(c -&gt; euler_eq(c, k, m.h; m), (c_min, c_max))\n            end\n        end\n\n        dist = maximum(abs, h_new .- m.h)\n        m.h .= h_new\n        iter += 1\n    end\n\n    if verbose\n        if iter == max_iter\n            println(\"Warning: Maximum iterations reached.\")\n        else\n            println(\"Converged in $iter iterations.\")\n        end\n    end\n\n    return nothing\nend\n\nm = Model()\npfi!(m)\nplot(m.k_grid, m.h, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Policy $h(k)$\")\n\nConverged in 5 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Policy Function Iteration.\n\n\n\n\nここから \\(k' := g(k) = f(k) + (1-\\delta)k - h(k)\\) が求められます. さらに, \\(h(k), g(k)\\) から価値関数 \\(V(k)\\) を求める方法は主に2つあります.\n\n\\(V(k) \\leftarrow u(h(k)) + \\beta V(g(k))\\) を用いて \\(V(k)\\) の不動点を求める方法 (VFI)\n線形方程式\n\n離散化された \\(k\\) から \\(k'\\) への遷移行列 \\(P\\) を求める. グリッド \\(k_i\\) が \\(k_j\\) と \\(k_{j+1}\\) の間に遷移する場合, 以下のように定義します.\n\n\\(P_{i, j} = \\frac{k_{j+1} - g(k_i)}{k_{j+1} - k_j}\\)\n\\(P_{i, j+1} = \\frac{g(k_i) - k_j}{k_{j+1} - k_j}\\)\n\\(P_{i, k} = 0\\), \\(k \\neq j, j+1\\)\n\n\\(u, V\\) を \\(u(h(k)), V(k)\\) からなる離散化されたベクトルとすると, \\(V = u + \\beta P V\\) となる\n\\(V = (I - \\beta P)^{-1} u\\) により \\(V\\) を求めることができる\n\n\nここでは, より高速な線型方程式を用いる方法を実装します. より速度を求める場合, 遷移行列はほとんどの要素がゼロであるため, 疎行列 (Sparse Matrix) を用いることで高速化する可能性があります. Juliaの場合, SparseArrays.jl で実装されています.\n\nfunction compute_vf!(m::Model)\n    (; h, n_k, k_grid, h, β, δ) = m\n    P = zeros(n_k, n_k)\n    for (i_k, k) in enumerate(k_grid)\n        g = f(k; m) + (1 - δ) * k - h[i_k]\n        j = searchsortedlast(k_grid, g)\n        if j == 1 || j == n_k\n            P[i_k, j] = 1.0\n        else\n            P[i_k, j] = (k_grid[j+1] - g) / (k_grid[j+1] - k_grid[j])\n            P[i_k, j+1] = (g - k_grid[j]) / (k_grid[j+1] - k_grid[j])\n        end\n    end\n\n    m.V .= (I - β * P) \\ (u.(h; m))\n\n    return nothing\nend\n\ncompute_vf!(m)\nplot(m.k_grid, m.V, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k)$\")\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Value Function from PFI and Linear Equation\n\n\n\n\nまた, VFIよりもPFIの方が収束速度が速いことも確認できますが, 実行速度も速いことも確認できます.\n\nusing BenchmarkTools\n@benchmark vfi!(m, verbose=false) setup = (m = Model())\n\n\nBenchmarkTools.Trial: 73 samples with 1 evaluation per sample.\n Range (min … max):  105.782 ms … 115.452 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     107.003 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   107.326 ms ±   1.393 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n     ▂  ▂██▂█▂ ▅█   ▂   ▂                                        \n  ██▁█▅▅██████▅████▅██▅▅██▁▅▅▅▁▅▁█▁█▁▁▁▁▅▁▁▅▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅ ▁\n  106 ms           Histogram: frequency by time          111 ms &lt;\n\n Memory estimate: 286.38 KiB, allocs estimate: 632.\n\n\n\n\n@benchmark (pfi!(m, verbose=false); compute_vf!(m)) setup = (m = Model())\n\n\nBenchmarkTools.Trial: 461 samples with 1 evaluation per sample.\n Range (min … max):   7.250 ms … 77.441 ms  ┊ GC (min … max):  0.00% … 82.81%\n Time  (median):      9.380 ms              ┊ GC (median):    15.02%\n Time  (mean ± σ):   10.823 ms ±  7.026 ms  ┊ GC (mean ± σ):  13.36% ± 11.06%\n\n  ▆▇▅▅█▇▅▂▁                 ▁                                  \n  █████████▆▄▁▅▁▅▄▁▄▁▄▅▁▁▁▄▆██▆▆▁▆▁▁▁▄▁▁▁▁▁▁▁▄▁▄▆▁▁▁▁▁▁▁▁▁▁▁▄ ▇\n  7.25 ms      Histogram: log(frequency) by time      35.2 ms &lt;\n\n Memory estimate: 17.33 MiB, allocs estimate: 38864."
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#確率的動学モデル",
    "href": "lecture/01-3-dynamic-model.html#確率的動学モデル",
    "title": "動学モデルの基礎",
    "section": "確率的動学モデル",
    "text": "確率的動学モデル\nこの節では確率的な不確実性を導入する. 生産関数 \\(f(k, z) = z k^\\alpha\\) とし, 生産性 \\(z\\) が確率的に変化するモデルを考えます. 生産性 \\(z\\) は以下のような AR(1) 過程に従うとします.\n\\[\n\\log z' = (1 - \\rho) \\mu + \\rho \\log z + \\sigma \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, 1).\n\\]\nこの時, ベルマン方程式は以下のように書き換えられます.\n\\[\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\mathbb{E}[V(k', z')| z]\\right\\}.\n\\]\nこの \\(V(k, z)\\) の数値計算するためには, \\(z\\) の状態空間を離散化する必要があります. ここでは, Tauchen Method (Tauchen 1986) を用いて \\(z\\) の状態空間を離散化します.\n\nTauchen Method\n実数列 \\(x_t\\) が以下のAR(1)過程に従うとします.\n\\[\nx_{t+1} = (1 - \\rho) \\mu + \\rho x_t + \\sigma \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, 1).\n\\]\nこれを \\(n\\) 個のグリッドポイント \\(\\{x_1, \\dots, x_n\\}\\) におけるマルコフ過程として離散化することを考えます. すなわち, 以下のような遷移確率行列 \\(\\Lambda\\) を考えます.\n\\[\n\\begin{pmatrix}\nx_{1, t+1} \\\\\n\\vdots \\\\\nx_{n, t+1}\n\\end{pmatrix} =\n\\begin{pmatrix}\n\\lambda_{1, 1} & \\cdots & \\lambda_{1, n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\lambda_{n, 1} & \\cdots & \\lambda_{n, n}\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{1, t} \\\\\n\\vdots \\\\\nx_{n, t}\n\\end{pmatrix}\n\\]\nここで, \\(\\lambda_{i, j} = \\Pr(x_{t+1} = x_j \\mid x_t = x_i)\\) であり, \\(\\sum_{j=1}^{n} \\lambda_{i, j} = 1\\) が成り立ちます. この遷移確率行列を求める方法として, Tauchen Method が知られています.\n\n\n\n\n\n\nNoteTauchen Method\n\n\n\n\n\\(x\\) の定義域 を \\([x_{\\min}, x_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する. 通常は \\(x\\) が従う分布の \\(3\\sigma\\) 程度の範囲を考える.\nグリッドポイント \\(x_i\\) から \\(x_j\\) に遷移する確率を以下のように定義する.\n\n\\[\n\\begin{aligned}\n\\lambda_{i, 1} &= \\Phi\\left(\\frac{x_1 + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) \\\\\n\\lambda_{i, j} &= \\Phi\\left(\\frac{x_j + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) - \\Phi\\left(\\frac{x_{j} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) & (2 \\leq j \\leq n-1) \\\\\n\\lambda_{i, n} &= 1 - \\Phi\\left(\\frac{x_{n} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right)\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nFigure 4: Visualization of Tauchen Method. \\(\\mu = 0\\).\n\n\n\n\nfunction tauchen_method(; n_std=3.0, n=5, ρ=0.9, μ=0.1, σ=1.0)\n\n    x_min = μ - n_std * sqrt(σ^2 / (1 - ρ^2))\n    x_max = μ + n_std * sqrt(σ^2 / (1 - ρ^2))\n    x = range(x_min, x_max, length=n)\n\n    d = (x_max - x_min) / (n - 1)\n    Λ = zeros(n, n)\n    for i in 1:n\n        Λ[i, 1] = cdf(Normal(0.0, σ), x[1] + d / 2 - (1 - ρ) * μ - ρ * x[i])\n        Λ[i, n] = 1 - cdf(Normal(0.0, σ), x[n] - d / 2 - (1 - ρ) * μ - ρ * x[i])\n        for j in 2:n-1\n            Λ[i, j] = cdf(Normal(0.0, σ), x[j] + d / 2 - (1 - ρ) * μ - ρ * x[i]) -\n                      cdf(Normal(0.0, σ), x[j] - d / 2 - (1 - ρ) * μ - ρ * x[i])\n        end\n    end\n\n    return x, Λ\nend\n\n\nx, Λ = tauchen_method()\n@show x\nΛ\n\nx = -6.782472016116854:3.4412360080584268:6.982472016116853\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\n実用上は QuantEcon.jl の tauchen 関数を利用するのがいいでしょう.\n\nusing QuantEcon\n\nmc = tauchen(5, 0.9, 1.0, 0.1) # tauchen(N, ρ, σ, μ)\n@show mc.state_values\nmc.p\n\nmc.state_values = -5.8824720161168536:3.4412360080584268:7.8824720161168536\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\nただし, ここでは AR(1) process が以下のように定義されていることに注意してください.\n\\[\ny_{t+1} = \\mu + \\rho y_{t} + \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, \\sigma^2).\n\\]\nそのため, \\(\\mathbb{E}[y_{t}] = \\frac{\\mu}{1-\\rho}\\) となります. 上の例では, \\(\\mu = 0.1\\), \\(\\rho = 0.9\\), \\(\\sigma = 1.0\\) としているため, \\(\\mathbb{E}[y_{t}] = 1.0\\) となります.\n\nps = vcat(stationary_distributions(mc)...)\nps' * collect(mc.state_values)\n\n1.0000000000000002\n\n\nAR(1) processの期待値を任意の値 \\(\\tilde{\\mu}\\) に設定するためには, \\(\\mu = (1-\\rho)\\tilde{\\mu}\\) とすればよいです.\n\nmc = tauchen(5, 0.9, 1.0, 0.01)\n@show mc.state_values\nmc.p\n\nmc.state_values = -6.782472016116854:3.4412360080584268:6.982472016116853\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\n\n\nValue Function Iteration\nAR(1) process を \\(\\Lambda\\) で離散化した後のベルマン方程式は以下のようになります.\n\\[\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\sum_{z'} \\Lambda(z, z') V(k', z')\\right\\}.\n\\]\nVFIを用いる場合, 実装は価値関数 \\(V\\) の次元を \\(z\\) のために1つ増やし, ベルマン方程式の通り実装するだけです.\n\n@kwdef struct StochasticModel{TF&lt;:AbstractFloat,TI&lt;:Integer}\n    # Parameters\n    α::TF = 0.4\n    β::TF = 0.96\n    δ::TF = 0.1\n    # AR(1) process\n    ρ::TF = 0.6\n    μ::TF = 0.0\n    σ::TF = 0.4\n\n    # Value Function\n    n_k::TI = 101\n    n_z::TI = 5\n    k_min::TF = 0.05\n    k_max::TF = 0.5\n    k_grid::Vector{TF} = collect(range(k_min, k_max, length=n_k))\n    mc::MarkovChain = tauchen(n_z, ρ, σ, μ)\n    z_grid::Vector{TF} = collect(exp.(mc.state_values))\n    Λ::Matrix{TF} = mc.p\n    V::Matrix{TF} = zeros(n_k, n_z)\nend\n\nf(k, z; m) = z * k^m.α\nfunction vfi!(m::StochasticModel; tol=1e-6, max_iter=1000)\n    (; k_grid, z_grid, β, δ, Λ) = m\n\n    iter, dist = 0, Inf\n    V_new = similar(m.V)\n    while dist &gt; tol && iter &lt; max_iter\n        for (i_z, z) in enumerate(z_grid), (i_k, k) in enumerate(k_grid)\n            c_min = 1e-9 # consumption cannot be negative\n            V_new[i_k, i_z] = maximum(\n                log(max(f(k, z; m) + (1 - δ) * k - k′, c_min)) +\n                β * sum(Λ[i_z, i_z′] * m.V[i_k′, i_z′]\n                        for (i_z′, z′) in enumerate(z_grid))\n                for (i_k′, k′) in enumerate(k_grid)\n            )\n        end\n\n        dist = maximum(abs, V_new .- m.V)\n        m.V .= V_new\n        iter += 1\n    end\n\n    if iter == max_iter\n        println(\"Warning: Maximum iterations reached.\")\n    else\n        println(\"Converged in $iter iterations.\")\n    end\n\n    return nothing\nend\n\n\nm = StochasticModel()\nvfi!(m)\np = plot(m.k_grid, m.V[:, 5], label=L\"z_5\", xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k, z)$\")\nfor i in 4:-1:1\n    plot!(m.k_grid, m.V[:, i], label=L\"z_%$i\")\nend\n\np\n\nConverged in 316 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Value Function of Stochastic Model."
  }
]