[
  {
    "objectID": "lecture/10-2-numerical-method.html",
    "href": "lecture/10-2-numerical-method.html",
    "title": "数値計算の補足",
    "section": "",
    "text": "Warning\n\n\n\nこのページは数値計算に関する補足を雑多にまとめたものです. 書きかけの内容を多く含みます.\nCode\nusing Plots\ndefault(size=(500, 309), titlefontsize=10, fmt=:svg)"
  },
  {
    "objectID": "lecture/10-2-numerical-method.html#計算量",
    "href": "lecture/10-2-numerical-method.html#計算量",
    "title": "数値計算の補足",
    "section": "計算量",
    "text": "計算量\nアルゴリズムの効率性を評価する尺度として、計算時間とメモリ使用量があります. ここでいう計算時間とは, アルゴリズムが終了するまでにかかるステップ数 (時間計算量, time complexity) のことをいい, 実際のPC上での実行時間とは異なります. より高いスペックのPCを使えば, 同じアルゴリズムでも実行時間は短くなる一方で, ステップ数の次元が異なるアルゴリズムはマシンの性能に関わらず効率的と言えます.また, メモリ使用量とはアルゴリズムが終了するまでに必要なメモリの量 (領域計算量, space complexity) のことをいいます.\n\n時間計算量\n時間計算量は, 入力の大きさ \\(n\\) に対するステップ数 \\(T(n)\\) の関数として表されます. 例えば, 配列の要素数が \\(n\\) のときに, すべての要素を1回ずつ見るアルゴリズムは, \\(T(n) = n\\) となります. また, 2重ループで配列のすべての組み合わせを調べるアルゴリズムは, \\(T(n) = n^2\\) となります. このように, アルゴリズムの時間計算量は, 入力の大きさに対するステップ数の増加率によって特徴づけられます.\n時間計算量を評価する際, 重要なのは支配的な項の次元数になります. 例えば, \\(T(n) = 3n^2 + 2n + 1\\) の場合, \\(n\\) が大きくなると \\(3n^2\\) の項が支配的になるため, \\(n^2\\) に着目すれば十分です. この考え方に従ったとき, 計算量を \\(O(n^2)\\) と表記します. より厳密に表現すると以下のようになります.\n\n\n\n\n\n\nNote\\(O\\)-記法\n\n\n\n\\(f(n)\\) が \\(O(g(n))\\) とは, 任意の \\(n \\ge 0\\) に対して, ある定数 \\(C &gt; 0\\) が存在して, 以下の不等式が成り立つことをいう.\n\\[\n|f(n)| \\le C |g(n)|.\n\\]\n\n\n定量モデルで気にする必要があるのは, ほとんどの場合, グリッド数によるオーダーです. 例えば, \\(V(k, z)\\) のような2次元の価値関数をグリッド上で計算する場合, \\(k\\) のグリッド数 \\(n_k\\) と \\(z\\) のグリッド数 \\(n_z\\) に対して, 計算量は \\(n_k n_z\\) の関数となります.\n\n\n領域計算量\n領域計算量は, アルゴリズムが終了するまでに必要なメモリの量を, 入力の大きさ \\(n\\) に対する関数として表します. 例えば, 配列の要素数が \\(n\\) のときに, すべての要素を保存するアルゴリズムは, 領域計算量が \\(O(n)\\) となります. また, 2次元配列を保存するアルゴリズムは, 領域計算量が \\(O(n^2)\\) となります.\nメモリのヒエラルキー\nなぜメモリの使用量が重要なのでしょうか. 近年のPCは何百GBもの容量があるし, いくら使おうと問題ではないのではないか, と思うかもしれません. しかし, 実際には, メモリのヒエラルキー (memory hierarchy) によって, メモリの速度と容量が大きく異なります.\n一般に, 高速なメモリは高価であるため搭載量が少なく, 低速なメモリは安価であるため搭載量が多いです. それらを合わせると 図 1 ようなピラミッド型のヒエラルキーが形成されます.\n\n\n\n\n\n\nFigure 1: Memory Hierarchy.\n\n\n\n\nレジスタ (Registers): CPU内部にある最も高速なメモリ\nキャッシュ (Cache): (近年では) CPU内部にある高速なメモリ. L1, L2, L3 などのレベルがある. ここまでCPU内部にある.\n主記憶 (Main Memory): RAM (Random Access Memory)\n補助記憶 (Auxiliary Storage): SSD (Solid State Drive) やHDD (Hard Disk Drive)\n\nたとえば, AMDの最新世代のCPUである Ryzen 5 9600 の場合, L1キャッシュは480KB, L2キャッシュは6MB, L3キャッシュは32MBです. レジスタはサイズで表現することはあまりありませんが, ざっくり数百B程度と考えてください. 一方で, 一般にメモリと呼ばれる RAM は8GBから64GB 程度が一般的です. さらに, 一般にストレージとよばれるSSDやHDDは数百GBから数TBの容量があります.\n\n\n計算量の実践\n実際にモデルを使って, 計算量を測定してみましょう. 例えば, 以下のような単純なライフサイクルモデルを考えます.\nModel\n\\[\n\\max_{\\{c_t, a_{t+1}\\}_{t=0}^{T-1}} \\sum_{t=0}^{T-1} \\beta^t u(c_t) \\\\\n\\quad\\text{s.t. } c_t + a_{t+1} = (1+r) a_t + w, \\quad a_0 \\text{ given}, \\quad a_T \\ge 0.\n\\]\nこれは後方帰納法で解くことができます. コードで表すと次の solve! 関数のようになります.\n\nmodule My\n\n@kwdef struct Model{TF&lt;:AbstractFloat,TI&lt;:Integer}\n\n    # Utility function\n    γ::TF = 2.0\n    β::TF = 0.96\n    T::Int = 10\n\n    # Prices\n    r::TF = 0.07\n    w::TF = 5.0\n\n    # Grid for assets\n    n_a::TI = 30\n    a_min::TF = 0.1\n    a_max::TF = 4.0\n    a_grid::Vector{TF} = collect(range(start=a_min, stop=a_max, length=n_a))\n\n    # Value function\n    V::Matrix{TF} = zeros(n_a, T)\nend\n\nu(c, m::Model) = isone(m.γ) ? log(c) : c^(1 - m.γ) / (1 - m.γ)\n\nfunction solve!(m::Model)\n    (; T, n_a, r, w, β, a_grid) = m\n\n    V = zeros(n_a, T)\n    for t = T:-1:1, i_a = 1:n_a\n\n        utility = -Inf\n        for i_a′ = 1:n_a\n            V′ = (t == T) ? 0.0 : V[i_a′, t+1]\n            c = (1 + r) * a_grid[i_a] + w - a_grid[i_a′]\n\n            if c &gt; 0\n                utility = max(u(c, m) + β * V′, utility)\n            end\n\n        end\n\n        V[i_a, t] = utility\n    end\n\n    m.V .= V\n\n    return nothing\nend\n\nend # module My\n\n時間計算量の数え方として, 四則演算, 比較 (&gt;, max など), 代入, 配列へのアクセスは \\(O(1)\\) とします. すると, 計算回数の主要部は for-loop つまり, \\(O(n_a^2 T)\\) です. メモリ使用量は, 価値関数 \\(V\\) の保存に使用している部分が支配的なので \\(O(n_a T)\\) です. では, \\(T = 10\\) で固定して, \\(n_a\\) を変化させたときの計算時間とメモリ使用量を測定してみましょう.\nBenchmarkTools.jl\nJuliaでは, BenchmarkTools.jl パッケージを使うと実際の計算時間とメモリ使用量を測定できます.1\n\nusing BenchmarkTools\n\n@benchmark My.solve!(m) setup = (m = My.Model(n_a=100))\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n Range (min … max):  382.625 μs …  11.432 ms  ┊ GC (min … max): 0.00% … 96.12%\n Time  (median):     404.334 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   407.738 μs ± 110.450 μs  ┊ GC (mean ± σ):  0.27% ±  0.96%\n\n                           ▁██▅▃▅▅▄▃▃▃▄▂▁▁▁ ▁▁▁                 ▂\n  ▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁████████████████████████▇▇▇▇▆▆▆▇▇▆▆▅ █\n  383 μs        Histogram: log(frequency) by time        431 μs &lt;\n\n Memory estimate: 8.08 KiB, allocs estimate: 3.\n\n\n\n@benchmark マクロは上記のように関数の実行時間に合わせて適切な試行回数を自動で決定し, 実行時間の分布を表示してくれます. 基本的には中央値 (median) を見るのが良いでしょう.\nメモリ使用量も8.08KiBと表示されています. 今回の配列 V は Float64 型の2次元配列で, \\(n_a\\) 行 \\(T\\) 列なので, メモリ使用量は \\(8 n_a T\\) バイトになります (64bit = 8バイト) . 例えば, \\(n_a = 100\\) のときは \\(8 \\times 100 \\times 10 = 8000\\) バイトで, 8.08KiB (1KiB = 1024バイト) とほぼ一致しています.\n次に \\(n_a = 1000\\) としたときの計算時間を測定してみましょう.\n\n@benchmark My.solve!(m) setup = (m = My.Model(n_a=1000))\n\n\nBenchmarkTools.Trial: 126 samples with 1 evaluation per sample.\n Range (min … max):  39.808 ms …  41.503 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     39.872 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   39.917 ms ± 180.200 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▂ ▃ █▇▄▄▃▁                                                    \n  ███▇██████▅▃▅▄▁▁▃▁▄▃▃▃▁▁▁▃▃▃▁▁▁▃▁▁▁▃▁▁▁▁▃▁▁▁▄▁▃▁▃▁▁▁▁▁▁▁▁▁▁▃ ▃\n  39.8 ms         Histogram: frequency by time         40.4 ms &lt;\n\n Memory estimate: 80.08 KiB, allocs estimate: 3.\n\n\n\nおおむね計算時間が100倍, メモリ使用量が10倍になっていることがわかります. これは, 計算時間が \\(O(n_a^2 T)\\), メモリ使用量が \\(O(n_a T)\\) であることと一致しています."
  },
  {
    "objectID": "lecture/10-2-numerical-method.html#微分",
    "href": "lecture/10-2-numerical-method.html#微分",
    "title": "数値計算の補足",
    "section": "微分",
    "text": "微分\n数値計算の文脈において微分は主に3種類あります.\n\n数式微分 (Symbolic Differentiation)\n数値微分 (Numerical Differentiation)\n自動微分 (Automatic Differentiation)\n\n数式微分 (手計算による解析的な微分) が可能な場合は, これが最も高速で効率的ですが, 複雑な関数に対しては, 数値微分や自動微分などで計算する必要があります. 以下では, 次のラグランジアンを例に, それぞれの微分方法を説明します.\n\\[\n\\mathcal{L} = \\phi \\log \\left(w(1-l)\\right)  + (1-\\phi) \\frac{l^{1-\\gamma}}{1-\\gamma}\n\\]\n\n数式微分 (Symbolic Differentiation)\nいわゆる手計算による微分です. 一階条件を求めると,\n\\[\n\\frac{\\partial \\mathcal{L}}{\\partial l} = -\\frac{\\phi}{1-l} + (1-\\phi) l^{-\\gamma} = 0.\n\\]\nSymbolics.jl パッケージを使うと, Julia上で数式微分を行うこともできます.\n\nusing Symbolics\nusing Latexify\n\n@variables w l ϕ γ\nL = ϕ * log(w * (1 - l)) + (1 - ϕ) * l^(1 - γ) / (1 - γ)\n∂l = Differential(l)\n∂L∂l = expand_derivatives(∂l(L))\nprintln(latexify(∂L∂l))\n\\[\\begin{equation}\n\\frac{ - \\phi}{1 - l} + l^{ - \\gamma} \\left( 1 - \\phi \\right)\n\\end{equation}\\]\n\n\n\n数値微分 (Numerical Differentiation)\n\\[\nf'(x) = \\lim_{\\Delta \\to 0} \\frac{f(x+\\Delta) - f(x)}{\\Delta}.\n\\]\n数値微分は上記の微分の定義を数値的に近似する方法です. 定義通りに行うと, 非常に小さい \\(d\\) (例えば \\(10^{-9}\\) など) を使って, 以下のように近似できます.\n\\[\nf'(x) \\approx \\frac{f(x+d) - f(x)}{d}.\n\\]\n実用上は, 中心差分 (central difference) を使うことが多いです.\n\\[\nf'(x) \\approx \\frac{f(x+\\frac{1}{2}d) - f(x-\\frac{1}{2}d)}{d}.\n\\]\nJulia では, FiniteDiff.jl パッケージを使うと数値微分ができます.\n\nusing FiniteDiff\nf(l; w=1., ϕ=0.5, γ=1.5) = ϕ * log(w * (1 - l)) + (1 - ϕ) * l^(1 - γ) / (1 - γ)\nf′_analytical(l; w=1., ϕ=0.5, γ=1.5) = -ϕ / (1 - l) + (1 - ϕ) * l^(-γ)\nf′_numerical(l; Δ=1e-9) = (f(l + 0.5 * Δ) - f(l - 0.5 * Δ)) / Δ\nf′_finitediff(l) = FiniteDiff.finite_difference_derivative(l -&gt; f(l), l)\n\n\n\nCode\nplot(0.2:0.01:0.9, f′_analytical, label=\"Analytical\")\nplot!(0.2:0.01:0.9, f′_numerical, label=\"Numerical\", linestyle=:dash)\nplot!(0.2:0.01:0.9, f′_finitediff, label=\"FiniteDiff.jl\", linestyle=:dot)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Comparison of analytical and numerical derivatives.\n\n\n\n\n\n\n自動微分 (Automatic Differentiation)\n数値微分はとてもシンプルな実装ですが, \\(d\\) の選び方によっては精度が悪くなる可能性があります. より高い精度を求める場合は, 自動微分を用いることができます. 自動微分は, 関数を基本的な演算 (多項式, 三角関数, 対数関数など) の組み合わせとして分解し, 各基本演算の微分を連鎖律に基づいて計算する方法です. これは, 数式微分を数値的に実行するようなイメージです.\n順伝播と逆伝播\n\\[\n\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}\n\\]\n\n順伝播 (forward mode): 入力から出力に向かって微分を計算する方法.\n\n\\(\\frac{du}{dx}\\) を計算し, それを用いて \\(\\frac{dy}{du}\\) を計算する.\n\n逆伝播 (reverse mode): 出力から入力に向かって微分を計算する方法.\n\n\\(\\frac{dy}{du}\\) を計算し, それを用いて \\(\\frac{du}{dx}\\) を計算する.\n\n\n一般に \\(f: \\mathbb{R}^m \\to \\mathbb{R}^n\\) に対して, \\(m &gt; n\\) の場合は逆伝播が効率的であり, \\(m &lt; n\\) の場合は順伝播が効率的です. 例えば, ニューラルネットワークでは, 多数のパラメータ (重み) を持つモデルに対して, 単一の損失関数を最小化するために逆伝播がよく使われます.\n順伝播の効率的な実装は双対数 (dual numbers) を用いて行えることが知られています. 一方, 逆伝播の効率的な実装は難しく, 様々な手法が提案されている状況です. 詳しくは, Perla, Sargent, and Stachurski (n.d.) の9.2節 を参照してください.\nJulia では, ForwardDiff.jl パッケージを使うと順伝播の自動微分ができます.\n\nusing ForwardDiff\nf′_forwarddiff(l) = ForwardDiff.derivative(l -&gt; f(l), l)\n\n\n\nCode\nplot(0.2:0.01:0.9, f′_analytical, label=\"Analytical\")\nplot!(0.2:0.01:0.9, f′_forwarddiff, label=\"ForwardDiff.jl\", linestyle=:dash)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Comparison of analytical and automatic derivatives."
  },
  {
    "objectID": "lecture/10-2-numerical-method.html#並列計算",
    "href": "lecture/10-2-numerical-method.html#並列計算",
    "title": "数値計算の補足",
    "section": "並列計算",
    "text": "並列計算\n現代のPCは複数のコアを持つマルチコアCPUを搭載しています. パッケージのバックグラウンドで並列計算が用いられていることもありますが, 基本的にはユーザーが明示的に並列計算を指示する必要があります.\nまずは, 自分のPCが何コア持っているかを確認してみましょう.\n\nThreads.nthreads()\n\n12\n\n\nここで, スレッド数が1となっている場合は, Juliaを起動する前に環境変数 JULIA_NUM_THREADS を設定する必要があります.\n\nQuarto: julia.exeflags: [\"--threads=auto\"] をYAMLヘッダーに追加\nVSCode: settings.json に \"julia.numThreads\": \"auto\" を追加\nターミナル: export JULIA_NUM_THREADS=auto を実行\n\nauto と設定した場合, 利用可能なコア数に応じて自動的にスレッド数が設定されます. 現代のPCであれば, ほとんどの場合, 利用可能なコア数が2以上になるはずです.\n\nfunction solve_multi!(m::My.Model)\n    (; T, n_a, r, w, β, a_grid) = m\n\n    V = zeros(n_a, T)\n    for t = T:-1:1\n        Threads.@threads for i_a = 1:n_a\n            utility = -Inf\n            for i_a′ = 1:n_a\n                V′ = (t == T) ? 0.0 : V[i_a′, t+1]\n                c = (1 + r) * a_grid[i_a] + w - a_grid[i_a′]\n\n                if c &gt; 0\n                    utility = max(My.u(c, m) + β * V′, utility)\n                end\n\n            end\n\n            V[i_a, t] = utility\n        end\n    end\n\n    m.V .= V\n\n    return nothing\nend\n\n\n@benchmark My.solve!(m) setup = (m = My.Model(n_a=1000))\n\n\nBenchmarkTools.Trial: 126 samples with 1 evaluation per sample.\n Range (min … max):  39.783 ms …  41.561 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     39.862 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   39.912 ms ± 223.887 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n    █▆                                                          \n  ▄▇██▇▃▃▃▁▂▁▁▁▃▁▂▂▁▁▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂ ▂\n  39.8 ms         Histogram: frequency by time         41.2 ms &lt;\n\n Memory estimate: 80.08 KiB, allocs estimate: 3.\n\n\n\n\n@benchmark solve_multi!(m) setup = (m = My.Model(n_a=1000))\n\n\nBenchmarkTools.Trial: 1222 samples with 1 evaluation per sample.\n Range (min … max):  3.862 ms …  15.492 ms  ┊ GC (min … max): 0.00% … 72.41%\n Time  (median):     3.990 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   4.080 ms ± 559.354 μs  ┊ GC (mean ± σ):  0.83% ±  4.27%\n\n    ▁█▆▃▂▁▁▁▁                                                  \n  ▅▆█████████▇▇▁▄▅▁▅▁▁▄▁▁▄▄▄▁▁▁▁▄▄▁▄▁▄▄▄▄▅▁▄▄▁▄▁▁▁▄▁▁▁▄▁▁▁▁▁▄ █\n  3.86 ms      Histogram: log(frequency) by time       5.8 ms &lt;\n\n Memory estimate: 181.02 KiB, allocs estimate: 863.\n\n\n\n並列化した場合, 1コアで実行した場合と比べて, おおむねスレッド数に応じて計算時間が短縮されていることがわかります. ただし, ここまで理論値に近い速度向上が得られることは稀で, 実際には理論値の数%から数十%程度の速度向上にとどまることが多いです.\n並列化できない計算\n並列計算の大前提は, 各スレッドが独立して計算できることです. 今回は後方帰納法で解くため, 時刻 \\(t\\) の価値関数を計算する際に, 時刻 \\(t+1\\) の価値関数が必要になり, 時刻方向に並列化することはできません."
  },
  {
    "objectID": "lecture/10-2-numerical-method.html#footnotes",
    "href": "lecture/10-2-numerical-method.html#footnotes",
    "title": "数値計算の補足",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n@time マクロでも簡易的に測定できますが, 関数の宣言によるコンパイル時間なども含んでしまうため, 関数の実行速度を正確に測定するには BenchmarkTools.jl パッケージを使うのが望ましいです.↩︎"
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html",
    "href": "lecture/01-3-dynamic-model.html",
    "title": "動学モデルの基礎",
    "section": "",
    "text": "using Plots\nusing LaTeXStrings\nusing Distributions\nimport Random\nusing Roots\nusing Optim\nusing LinearAlgebra\nusing Interpolations\nusing SpecialFunctions\ndefault(size=(500, 309), titlefontsize=10, fmt=:svg)"
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#グリッドと補完",
    "href": "lecture/01-3-dynamic-model.html#グリッドと補完",
    "title": "動学モデルの基礎",
    "section": "グリッドと補完",
    "text": "グリッドと補完\n未知なる関数 \\(f(x)\\) の一般形が分からないが, 具体的な \\(x\\) に関しては \\(f(x)\\) の値が計算できる状況というのがよくあります. ちょっと極端な例を考えてみましょう. 次の効用最大化問題を考えます.\n\\[\n\\max_{n} \\log c - \\Phi(n) \\text{ s.t.　}　c = w n.\n\\]\nここで, 労働供給の不効用 \\(\\Phi(n) = \\phi \\log (n!)\\) とします. この時の最適な \\(n^*\\) を求めてみましょう.\n\nΦ(n::Int; ϕ=0.1) = ϕ * sum(log(i) for i in 1:n)\nu(n::Int; w=1.) = log(n) - Φ(n)\n\nGrid Search\n最も単純な方法は, \\(n = 1, \\dots, 10\\) ぐらいまで試してみて, 最も効用 \\(u(c, n)\\) が大きくなる \\(n\\) を選ぶ方法です. これをグリッドサーチと呼びます.\n\n\nCode\nscatter(1:10, u, label=false, xlabel=L\"n\", ylabel=L\"u(c, n)\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Grid Search for Optimal n. \\(ϕ = 0.1\\).\n\n\n\n\n\nargmax(u, 1:10)\n\n6\n\n\n補完 (Interpolation)\nこれを実数の世界に拡張してみましょう. もし, \\(n\\) が実数の時の \\(\\Phi(n)\\) の値が計算できれば, 通常の一変数関数の最大化問題として解くことができます. そのために, \\(\\Phi(n)\\) を補完 (interpolation) してみましょう. Juliaでは Interpolations.jl パッケージを用います.\n\nn_grid = 1:10\nΦ_grid = Φ.(n_grid)\nΦ_interp = linear_interpolation(n_grid, Φ_grid)\nΦ_spline = Interpolations.scale(\n    interpolate(Φ_grid, BSpline(Cubic(Line(OnGrid())))),\n    n_grid\n)\n\n\n\nCode\nscatter(1:10, Φ, label=\"Grid Points\", xlabel=L\"n\", ylabel=L\"\\Phi(n)\")\nplot!(1:0.1:10, n -&gt; Φ_interp(n), label=\"Linear Interpolation\", legend=:topleft)\nplot!(1:0.1:10, n -&gt; Φ_spline(n), label=\"Cubic Spline\", linestyle=:dash)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Linear and Spline Interpolation of Cost Function \\(\\Phi(n)\\).\n\n\n\n\nここでは線形補間 (linear interpolation) と3次スプライン補間 (cubic spline interpolation) の両方を定義しました. 線形補間は2点間を直線で結ぶだけですが, スプライン補間はより滑らかな曲線で補間します. 詳細は 北尾, 砂川, and 山田 (2024) の付録Bが参考になります.\nこのように実数上に定義された関数を用いれば, 通常の最適化問題のように解くことができます.1\n\nu_interp(n) = log(n) - Φ_interp(n)\nu_spline(n) = log(n) - Φ_spline(n)\n\nsol_interp = optimize(n -&gt; -u_interp(n), 1.0, 10.0)\nsol_spline = optimize(n -&gt; -u_spline(n), 1.0, 10.0)\n\nprintln(\"Linear Interpolation: n = $(round(sol_interp.minimizer, digits=4))\")\nprintln(\"Cubic Spline: n = $(round(sol_spline.minimizer, digits=4))\")\n\nLinear Interpolation: n = 5.5811\nCubic Spline: n = 5.5516\n\n\n今回の例では, 階乗はガンマ関数 を用いて実数に拡張できるので, より厳密な解を求めることもできます.\n\n\nCode\nΦ(n::Real; ϕ=0.1) = ϕ * loggamma(n + 1)\nu_exact(n) = log(n) - Φ(n)\nsol_exact = optimize(n -&gt; -u_exact(n), 1.0, 10.0)\nprintln(\"Exact Solution: n = $(round(sol_exact.minimizer, digits=4))\")\n\n\nExact Solution: n = 5.5512"
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#ベルマン方程式の数値解法",
    "href": "lecture/01-3-dynamic-model.html#ベルマン方程式の数値解法",
    "title": "動学モデルの基礎",
    "section": "ベルマン方程式の数値解法",
    "text": "ベルマン方程式の数値解法\n以下の無限期間代表的個人のモデルを考えます.\n\\[\n\\max_{\\{c_t, k_{t+1}\\}_{t=0}^{\\infty}} \\sum_{t=0}^{\\infty} \\beta^t u(c_t) \\quad \\text{s.t.} \\quad c_t + k_{t+1} = f(k_t) + (1-\\delta)k_t.\n\\]\nこれをベルマン方程式 \\(V(k)\\) に書き換えた時の数値解法を考えます.\n\\[\nV(k) = \\max_{k'} \\left\\{u(f(k) + (1-\\delta)k - k') + \\beta V(k')\\right\\}\n\\]\n大きく分けて, 2つの方法があります.\n\nValue Function Iteration\n\nベルマン方程式の不動点を直接求める方法\n収束性が保証されているが, 収束速度は比較的遅い\n\nPolicy Function Iteration\n\nオイラー方程式の不動点を求める方法\n収束性は保証されていないが, 収束速度は比較的速い\n\n\n数値計算に用いるために, 以下の関数形とパラメータを仮定します.\n\n\\(u(c) = \\log c\\)\n\\(f(k) = k^\\alpha\\)\n\\(\\beta = 0.96\\)\n\\(\\delta = 0.1\\)\n\\(\\alpha = 0.36\\)\n\n\n@kwdef struct Model{TF&lt;:AbstractFloat,TI&lt;:Integer}\n    # Parameters\n    α::TF = 0.4\n    β::TF = 0.96\n    δ::TF = 0.1\n\n    # Value Function\n    n_k::TI = 101\n    k_min::TF = 0.05\n    k_max::TF = 0.5\n    k_grid::Vector{TF} = collect(range(k_min, k_max, length=n_k))\n    V::Vector{TF} = zeros(n_k)\n    h::Vector{TF} = copy(k_grid)\nend\n\nu(c; m) = log(c)\nu′(c; m) = 1 / c\nf(k; m) = k^m.α\nf′(k; m) = m.α * k^(m.α - 1)\n\n\nValue Function Iteration\n\n\n\n\n\n\nNoteValue Function Iteration\n\n\n\n\n\\(k\\) の定義域を \\([k_{\\min}, k_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する.\n\\(V(k)\\) の初期値 \\(V^0\\) を適当に設定する. つまり, \\(V^0 = (V_0^0, V_1^0, \\dots, V_n^0)\\) に適当な値を設定する.\n\\(V^0\\) をベルマン方程式の右辺に代入し, 各 \\(k_i\\) に対して \\(V_i^1\\) を計算する.\n2-3を繰り返す. 収束条件は以下のように設定する.\n\n\\(|V^N - V^{N-1}| &lt; \\varepsilon\\)\n\\(|V^N - V^{N-1}|\\) はベクトルのノルム\n\\(\\varepsilon\\) は十分小さな値を設定する. 例えば, \\(\\epsilon = 10^{-6}\\) とする\n\n\n\n\nなおこのような収束の閾値 \\(\\varepsilon\\) を tolerance と呼ぶことがあります.\n\nfunction vfi!(m::Model; tol=1e-6, max_iter=1000, verbose=true)\n    (; k_grid, β, δ) = m\n\n    iter, dist = 0, Inf\n    V_new = similar(m.V)\n    while dist &gt; tol && iter &lt; max_iter\n        for (i_k, k) in enumerate(k_grid)\n            c_min = 1e-9 # consumption cannot be negative\n            V_new[i_k] = maximum(\n                log(max(f(k; m) + (1 - δ) * k - k′, c_min)) + β * m.V[i_k′]\n                for (i_k′, k′) in enumerate(k_grid)\n            )\n        end\n\n        dist = maximum(abs, V_new - m.V)\n        m.V .= V_new\n        iter += 1\n    end\n\n    if verbose\n        if iter == max_iter\n            println(\"Warning: Maximum iterations reached.\")\n        else\n            println(\"Converged in $iter iterations.\")\n        end\n    end\n\n    return nothing\nend\n\n\nm = Model()\nvfi!(m)\nplot(m.k_grid, m.V, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k)$\")\n\nConverged in 315 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Value Function Iteration\n\n\n\n\nなお, 各イタレーションでは, \\(k\\) に対する最適な \\(k'\\) や \\(c\\) を求めています. それらを記録しておくことで, 政策関数 \\(c = h(k)\\) や \\(k' = g(k)\\) を求めることができます.\n\n\nPolicy Function Iteration\n上記のベルマン方程式から, 以下のオイラー方程式が導出されます.\n\\[\nu'(c) = \\beta u'(c')\\left(f'(k') + (1-\\delta)\\right).\n\\]\nここで, 政策関数 \\(c' = h(k')\\) と予算制約 \\(k' = f(k) + (1-\\delta)k - c\\) を導入すると, 上記のオイラー方程式は以下のように書き換えられます.\n\\[\nu'(c) = \\beta u'(h(f(k) + (1-\\delta)k - c))\\left(f'(f(k) + (1-\\delta)k - c) + (1-\\delta)\\right).\n\\]\nこの時, \\(h(k)\\) を所与とした時に \\(c\\) について解くと新しい政策関数 \\(h(k)\\) が得られます. この政策関数繰り返し更新することで, 政策関数の不動点を求めることができます.\n\n\n\n\n\n\nNotePolicy Function Iteration\n\n\n\n\n\\(k\\) の定義域を \\([k_{\\min}, k_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する\n\\(h(k)\\) の初期値 \\(h^0\\) を適当に設定する. つまり, \\(h^0 = (h_0^0, h_1^0, \\dots, h_n^0)\\) に適当な値を設定する.\n\\(h^0\\) をオイラー方程式の右辺に代入し, 各 \\(k_i\\) に対して \\(h_i^1\\) を計算する.\n2-3を繰り返す. 収束条件は以下のように設定する.\n\n\\(|h^N - h^{N-1}| &lt; \\varepsilon\\)\n\\(|h^N - h^{N-1}|\\) はベクトルのノルム\n\\(\\varepsilon\\) は十分小さな値を設定する. 例えば, \\(\\epsilon = 10^{-6}\\) とする\n\n\n\n\n\nfunction euler_eq(c, k, h; m)\n    (; β, δ, k_grid) = m\n\n    k′ = max(f(k; m) + (1 - δ) * k - c, k_grid[begin])\n    h_interp = linear_interpolation(k_grid, h)\n    c′ = h_interp(k′)\n\n    return u′(c; m) - β * u′(c′; m) * (f′(k′; m) + 1 - δ)\nend\n\nfunction pfi!(m::Model; tol=1e-6, max_iter=1000, verbose=true)\n    (; k_min, k_max, k_grid, α, β, δ) = m\n\n    h_new = similar(m.h)\n    iter, dist = 0, Inf\n    while dist &gt; tol && iter &lt; max_iter\n\n        for (i_k, k) in enumerate(k_grid)\n            c_min = max(1e-9, f(k; m) + (1 - δ) * k - k_grid[end])\n            c_max = f(k; m) + (1 - δ) * k - k_grid[begin]\n            ee_left = euler_eq(c_min, k, m.h; m)\n            ee_right = euler_eq(c_max, k, m.h; m)\n            if ee_left &gt; 0 && ee_right &gt; 0\n                h_new[i_k] = c_max\n            elseif ee_left &lt; 0 && ee_right &lt; 0\n                h_new[i_k] = c_min\n            else\n                h_new[i_k] = find_zero(c -&gt; euler_eq(c, k, m.h; m), (c_min, c_max))\n            end\n        end\n\n        dist = maximum(abs, h_new .- m.h)\n        m.h .= h_new\n        iter += 1\n    end\n\n    if verbose\n        if iter == max_iter\n            println(\"Warning: Maximum iterations reached.\")\n        else\n            println(\"Converged in $iter iterations.\")\n        end\n    end\n\n    return nothing\nend\n\nm = Model()\npfi!(m)\nplot(m.k_grid, m.h, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Policy $h(k)$\")\n\nConverged in 5 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Policy Function Iteration.\n\n\n\n\nここから \\(k' := g(k) = f(k) + (1-\\delta)k - h(k)\\) が求められます. さらに, \\(h(k), g(k)\\) から価値関数 \\(V(k)\\) を求める方法は主に2つあります.\n\n\\(V(k) \\leftarrow u(h(k)) + \\beta V(g(k))\\) を用いて \\(V(k)\\) の不動点を求める方法 (VFI)\n線形方程式\n\n離散化された \\(k\\) から \\(k'\\) への遷移行列 \\(P\\) を求める. グリッド \\(k_i\\) が \\(k_j\\) と \\(k_{j+1}\\) の間に遷移する場合, 以下のように定義します.\n\n\\(P_{i, j} = \\frac{k_{j+1} - g(k_i)}{k_{j+1} - k_j}\\)\n\\(P_{i, j+1} = \\frac{g(k_i) - k_j}{k_{j+1} - k_j}\\)\n\\(P_{i, k} = 0\\), \\(k \\neq j, j+1\\)\n\n\\(u, V\\) を \\(u(h(k)), V(k)\\) からなる離散化されたベクトルとすると, \\(V = u + \\beta P V\\) となる\n\\(V = (I - \\beta P)^{-1} u\\) により \\(V\\) を求めることができる\n\n\nここでは, より高速な線型方程式を用いる方法を実装します. より速度を求める場合, 遷移行列はほとんどの要素がゼロであるため, 疎行列 (Sparse Matrix) を用いることで高速化する可能性があります. Juliaの場合, SparseArrays.jl で実装されています.\n\nfunction compute_vf!(m::Model)\n    (; h, n_k, k_grid, h, β, δ) = m\n    P = zeros(n_k, n_k)\n    for (i_k, k) in enumerate(k_grid)\n        g = f(k; m) + (1 - δ) * k - h[i_k]\n        j = searchsortedlast(k_grid, g)\n        if j == 1 || j == n_k\n            P[i_k, j] = 1.0\n        else\n            P[i_k, j] = (k_grid[j+1] - g) / (k_grid[j+1] - k_grid[j])\n            P[i_k, j+1] = (g - k_grid[j]) / (k_grid[j+1] - k_grid[j])\n        end\n    end\n\n    m.V .= (I - β * P) \\ (u.(h; m))\n\n    return nothing\nend\n\ncompute_vf!(m)\nplot(m.k_grid, m.V, label=false, xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k)$\")\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Value Function from PFI and Linear Equation\n\n\n\n\nまた, VFIよりもPFIの方が収束速度が速いことも確認できますが, 実行速度も速いことも確認できます.\n\nusing BenchmarkTools\n@benchmark vfi!(m, verbose=false) setup = (m = Model())\n\n\nBenchmarkTools.Trial: 68 samples with 1 evaluation per sample.\n Range (min … max):  73.294 ms …  75.415 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     73.391 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   73.501 ms ± 366.646 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▇█▄                                                          \n  ▇███▆▄▄▁▃▄▁▃▁▁▃▃▃▁▃▁▃▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▁\n  73.3 ms         Histogram: frequency by time         75.3 ms &lt;\n\n Memory estimate: 286.38 KiB, allocs estimate: 632.\n\n\n\n\n@benchmark (pfi!(m, verbose=false); compute_vf!(m)) setup = (m = Model())\n\n\nBenchmarkTools.Trial: 971 samples with 1 evaluation per sample.\n Range (min … max):  4.730 ms …  14.693 ms  ┊ GC (min … max): 0.00% … 66.28%\n Time  (median):     5.113 ms               ┊ GC (median):    6.59%\n Time  (mean ± σ):   5.148 ms ± 483.284 μs  ┊ GC (mean ± σ):  6.15% ±  4.32%\n\n   ▂▂▁              ▇█▆▃          ▁                            \n  ▆████▆▅▅▅▅▁▁▅▁▄▄▁▆██████▆▅▆▆▄▇█▅█▇▅▅▇▆▆▆▅▁▅▁▁▁▄▄▁▄▁▁▅▄▄▁▁▁▄ █\n  4.73 ms      Histogram: log(frequency) by time      5.89 ms &lt;\n\n Memory estimate: 17.28 MiB, allocs estimate: 38533."
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#確率的動学モデル",
    "href": "lecture/01-3-dynamic-model.html#確率的動学モデル",
    "title": "動学モデルの基礎",
    "section": "確率的動学モデル",
    "text": "確率的動学モデル\nこの節では確率的な不確実性を導入する. 生産関数 \\(f(k, z) = z k^\\alpha\\) とし, 生産性 \\(z\\) が確率的に変化するモデルを考えます. 生産性 \\(z\\) は以下のような AR(1) 過程に従うとします.\n\\[\n\\log z' = (1 - \\rho) \\mu + \\rho \\log z + \\sigma \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, 1).\n\\]\nこの時, ベルマン方程式は以下のように書き換えられます.\n\\[\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\mathbb{E}[V(k', z')| z]\\right\\}.\n\\]\nこの \\(V(k, z)\\) の数値計算するためには, \\(z\\) の状態空間を離散化する必要があります. ここでは, Tauchen Method (Tauchen 1986) を用いて \\(z\\) の状態空間を離散化します.\n\nTauchen Method\n実数列 \\(x_t\\) が以下のAR(1)過程に従うとします.\n\\[\nx_{t+1} = (1 - \\rho) \\mu + \\rho x_t + \\sigma \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, 1).\n\\]\nこれを \\(n\\) 個のグリッドポイント \\(\\{x_1, \\dots, x_n\\}\\) におけるマルコフ過程として離散化することを考えます. すなわち, 以下のような遷移確率行列 \\(\\Lambda\\) を考えます.\n\\[\n\\begin{pmatrix}\nx_{1, t+1} \\\\\n\\vdots \\\\\nx_{n, t+1}\n\\end{pmatrix} =\n\\begin{pmatrix}\n\\lambda_{1, 1} & \\cdots & \\lambda_{1, n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\lambda_{n, 1} & \\cdots & \\lambda_{n, n}\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{1, t} \\\\\n\\vdots \\\\\nx_{n, t}\n\\end{pmatrix}\n\\]\nここで, \\(\\lambda_{i, j} = \\Pr(x_{t+1} = x_j \\mid x_t = x_i)\\) であり, \\(\\sum_{j=1}^{n} \\lambda_{i, j} = 1\\) が成り立ちます. この遷移確率行列を求める方法として, Tauchen Method が知られています.\n\n\n\n\n\n\nNoteTauchen Method\n\n\n\n\n\\(x\\) の定義域 を \\([x_{\\min}, x_{\\max}]\\) を \\(n\\) 個のグリッドポイントに分割する. 通常は \\(x\\) が従う分布の \\(3\\sigma\\) 程度の範囲を考える.\nグリッドポイント \\(x_i\\) から \\(x_j\\) に遷移する確率を以下のように定義する.\n\n\\[\n\\begin{aligned}\n\\lambda_{i, 1} &= \\Phi\\left(\\frac{x_1 + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) \\\\\n\\lambda_{i, j} &= \\Phi\\left(\\frac{x_j + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) - \\Phi\\left(\\frac{x_{j} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) & (2 \\leq j \\leq n-1) \\\\\n\\lambda_{i, n} &= 1 - \\Phi\\left(\\frac{x_{n} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right)\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nFigure 6: Visualization of Tauchen Method. \\(\\mu = 0\\).\n\n\n\n\nfunction tauchen_method(; n_std=3.0, n=5, ρ=0.9, μ=0.1, σ=1.0)\n\n    x_min = μ - n_std * sqrt(σ^2 / (1 - ρ^2))\n    x_max = μ + n_std * sqrt(σ^2 / (1 - ρ^2))\n    x = range(x_min, x_max, length=n)\n\n    d = (x_max - x_min) / (n - 1)\n    Λ = zeros(n, n)\n    for i in 1:n\n        Λ[i, 1] = cdf(Normal(0.0, σ), x[1] + d / 2 - (1 - ρ) * μ - ρ * x[i])\n        Λ[i, n] = 1 - cdf(Normal(0.0, σ), x[n] - d / 2 - (1 - ρ) * μ - ρ * x[i])\n        for j in 2:n-1\n            Λ[i, j] = cdf(Normal(0.0, σ), x[j] + d / 2 - (1 - ρ) * μ - ρ * x[i]) -\n                      cdf(Normal(0.0, σ), x[j] - d / 2 - (1 - ρ) * μ - ρ * x[i])\n        end\n    end\n\n    return x, Λ\nend\n\n\nx, Λ = tauchen_method()\n@show x\nΛ\n\nx = -6.782472016116854:3.4412360080584268:6.982472016116853\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\n実用上は QuantEcon.jl の tauchen 関数を利用するのがいいでしょう.\n\nusing QuantEcon\n\nmc = tauchen(5, 0.9, 1.0, 0.1) # tauchen(N, ρ, σ, μ)\n@show mc.state_values\nmc.p\n\nmc.state_values = -5.8824720161168536:3.4412360080584268:7.8824720161168536\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\nただし, ここでは AR(1) process が以下のように定義されていることに注意してください.\n\\[\ny_{t+1} = \\mu + \\rho y_{t} + \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, \\sigma^2).\n\\]\nそのため, \\(\\mathbb{E}[y_{t}] = \\frac{\\mu}{1-\\rho}\\) となります. 上の例では, \\(\\mu = 0.1\\), \\(\\rho = 0.9\\), \\(\\sigma = 1.0\\) としているため, \\(\\mathbb{E}[y_{t}] = 1.0\\) となります.\n\nps = vcat(stationary_distributions(mc)...)\nps' * collect(mc.state_values)\n\n1.0\n\n\nAR(1) processの期待値を任意の値 \\(\\tilde{\\mu}\\) に設定するためには, \\(\\mu = (1-\\rho)\\tilde{\\mu}\\) とすればよいです.\n\nmc = tauchen(5, 0.9, 1.0, 0.01)\n@show mc.state_values\nmc.p\n\nmc.state_values = -6.782472016116854:3.4412360080584268:6.982472016116853\n\n\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n\n\n\n\nValue Function Iteration\nAR(1) process を \\(\\Lambda\\) で離散化した後のベルマン方程式は以下のようになります.\n\\[\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\sum_{z'} \\Lambda(z, z') V(k', z')\\right\\}.\n\\]\nVFIを用いる場合, 実装は価値関数 \\(V\\) の次元を \\(z\\) のために1つ増やし, ベルマン方程式の通り実装するだけです.\n\n@kwdef struct StochasticModel{TF&lt;:AbstractFloat,TI&lt;:Integer}\n    # Parameters\n    α::TF = 0.4\n    β::TF = 0.96\n    δ::TF = 0.1\n    # AR(1) process\n    ρ::TF = 0.6\n    μ::TF = 0.0\n    σ::TF = 0.4\n\n    # Value Function\n    n_k::TI = 101\n    n_z::TI = 5\n    k_min::TF = 0.05\n    k_max::TF = 0.5\n    k_grid::Vector{TF} = collect(range(k_min, k_max, length=n_k))\n    mc::MarkovChain = tauchen(n_z, ρ, σ, μ)\n    z_grid::Vector{TF} = collect(exp.(mc.state_values))\n    Λ::Matrix{TF} = mc.p\n    V::Matrix{TF} = zeros(n_k, n_z)\nend\n\nf(k, z; m) = z * k^m.α\nfunction vfi!(m::StochasticModel; tol=1e-6, max_iter=1000)\n    (; k_grid, z_grid, β, δ, Λ) = m\n\n    iter, dist = 0, Inf\n    V_new = similar(m.V)\n    while dist &gt; tol && iter &lt; max_iter\n        for (i_z, z) in enumerate(z_grid), (i_k, k) in enumerate(k_grid)\n            c_min = 1e-9 # consumption cannot be negative\n            V_new[i_k, i_z] = maximum(\n                log(max(f(k, z; m) + (1 - δ) * k - k′, c_min)) +\n                β * sum(Λ[i_z, i_z′] * m.V[i_k′, i_z′]\n                        for (i_z′, z′) in enumerate(z_grid))\n                for (i_k′, k′) in enumerate(k_grid)\n            )\n        end\n\n        dist = maximum(abs, V_new .- m.V)\n        m.V .= V_new\n        iter += 1\n    end\n\n    if iter == max_iter\n        println(\"Warning: Maximum iterations reached.\")\n    else\n        println(\"Converged in $iter iterations.\")\n    end\n\n    return nothing\nend\n\n\nm = StochasticModel()\nvfi!(m)\np = plot(m.k_grid, m.V[:, 5], label=L\"z_5\", xlabel=L\"Capital $k$\", ylabel=L\"Value $V(k, z)$\")\nfor i in 4:-1:1\n    plot!(m.k_grid, m.V[:, i], label=L\"z_%$i\")\nend\n\np\n\nConverged in 316 iterations.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Value Function of Stochastic Model."
  },
  {
    "objectID": "lecture/01-3-dynamic-model.html#footnotes",
    "href": "lecture/01-3-dynamic-model.html#footnotes",
    "title": "動学モデルの基礎",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n線形補間では一階微分までしかとれませんが, スプライン補間を用いれば二階微分が取れるので, derivative-based な最適化手法も使えます. ここでは1変数関数なので, bracketing method のような微分のいらない手法を用いています.↩︎"
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture Materials",
    "section": "",
    "text": "2025年10月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月20日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood and Guner (2009)\n\n\n\n\n\n2025年10月27日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood et al. (2016)\n\n\n\n\n\n2025年11月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGayle and Shephard (2019)\n\n\n\n\n\n2025年11月10日\n\n\n\n\n\n\n\n\n\n\n\n\n\nReynoso (2024)\n\n\n\n\n\n2025年11月17日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoepke et al. (2023)\n\n\n\n\n\n2025年12月1日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood, Guner, and Marto (2023)\n\n\n\n\n\n2025年12月8日\n\n\n\n\n\n\n\n\n\n\n\n\n\nKim, Tertilt, and Yum (2024)\n\n\n\n\n\n2025年12月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdda, Dustmann, and Stevens (2017)\n\n\n\n\n\n2025年12月22日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErosa et al. (2022)\n\n\n\n\n\n2026年1月5日\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalvo, Lindenlaub, and Reynoso (2024)\n\n\n\n\n\n2026年1月14日\n\n\n\n\n\n\n\n\n\n\n\n\n\nLise and Yamada (2019)\n\n\n\n\n\n2026年1月19日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture.html#講義資料",
    "href": "lecture.html#講義資料",
    "title": "Lecture Materials",
    "section": "",
    "text": "2025年10月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年10月20日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood and Guner (2009)\n\n\n\n\n\n2025年10月27日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood et al. (2016)\n\n\n\n\n\n2025年11月6日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGayle and Shephard (2019)\n\n\n\n\n\n2025年11月10日\n\n\n\n\n\n\n\n\n\n\n\n\n\nReynoso (2024)\n\n\n\n\n\n2025年11月17日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoepke et al. (2023)\n\n\n\n\n\n2025年12月1日\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreenwood, Guner, and Marto (2023)\n\n\n\n\n\n2025年12月8日\n\n\n\n\n\n\n\n\n\n\n\n\n\nKim, Tertilt, and Yum (2024)\n\n\n\n\n\n2025年12月15日\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdda, Dustmann, and Stevens (2017)\n\n\n\n\n\n2025年12月22日\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErosa et al. (2022)\n\n\n\n\n\n2026年1月5日\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalvo, Lindenlaub, and Reynoso (2024)\n\n\n\n\n\n2026年1月14日\n\n\n\n\n\n\n\n\n\n\n\n\n\nLise and Yamada (2019)\n\n\n\n\n\n2026年1月19日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture.html#appendix",
    "href": "lecture.html#appendix",
    "title": "Lecture Materials",
    "section": "Appendix",
    "text": "Appendix\n\n\n\n\n\n\n\n\n\n\nJuliaの基礎\n\n\n\n\n\n\n\n\n2025年10月1日\n\n\n\n\n\n\n\n\n\n\n\n\n数値計算の補足\n\n\n\n\n\n\n\n\n2025年10月11日\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "",
    "text": "Kazuharu Yanagimoto\n        \n        \n            Macro IV・Fall 2025Kobe University"
  },
  {
    "objectID": "index.html#スケジュール",
    "href": "index.html#スケジュール",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "スケジュール",
    "text": "スケジュール\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                \n                タイトル\n                教材\n                課題提出\n              \n        \n        \n        \n                \n                  基礎編\n                  基礎編\n                  基礎編\n                  基礎編\n                \n                \n                  2025-10-06\n                  Introduction\n                  \n                   \n                \n                \n                  2025-10-15\n                  数値計算の基礎\n                  \n                   \n                \n                \n                  2025-10-20\n                  動学モデルの基礎\n                  \n                  2025-10-28\n                \n                \n                  結婚の経済学\n                  結婚の経済学\n                  結婚の経済学\n                  結婚の経済学\n                \n                \n                  2025-10-27\n                  Search and Matching I\n                  \n                   \n                \n                \n                  2025-11-06\n                  Search and Matching II\n                  \n                   \n                \n                \n                  2025-11-10\n                  Frictionless Marriage Market I\n                  \n                   \n                \n                \n                  2025-11-17\n                  Frictionless Marriage Market II\n                  \n                  2025-12-02\n                \n                \n                  出生の経済学\n                  出生の経済学\n                  出生の経済学\n                  出生の経済学\n                \n                \n                  2025-12-01\n                  Old Facts, Old Models\n                  \n                   \n                \n                \n                  2025-12-08\n                  Kuznet's Facts for Family Economists\n                  \n                   \n                \n                \n                  2025-12-15\n                  New Theory of Fertility I\n                  \n                   \n                \n                \n                  2025-12-22\n                  New Theory of Fertility II\n                  \n                   \n                \n                \n                  ジェンダー格差\n                  ジェンダー格差\n                  ジェンダー格差\n                  ジェンダー格差\n                \n                \n                  2026-01-05\n                  Non-linear Wage\n                  \n                   \n                \n                \n                  2026-01-14\n                  Home Production\n                  \n                   \n                \n                \n                  2026-01-19\n                  Intra-household Allocation\n                  \n                  2025-01-29\n                \n                \n                  まとめ\n                  まとめ\n                  まとめ\n                  まとめ\n                \n                \n                  2026-01-26\n                  まとめ\n                   \n                   \n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\nTipSubscribe!\n\n\n\n授業スケジュールをGoogle Calendarなどに登録できます. 私個人のために作成したものであり間違いがある可能性があります. 大学からの正式なスケジュールを優先した上で, 参考程度にご利用ください."
  },
  {
    "objectID": "index.html#課題について",
    "href": "index.html#課題について",
    "title": "\n            Family Macroeconomics\n        ",
    "section": "課題について",
    "text": "課題について\n提出期限\n\n対応するTAセッションの前日23:59 (JST)\n例: 10月29日のTAセッション → 10月28日23:59まで\n\n提出方法\n\nBeef+上でPDFレポートとコードをアップロード\nTAのPC上で動作確認を行う. 再現できない場合は, TAが環境について質問することがある\n\nコードについて\n\nTAのPC上で動作確認を行うため, 無料で利用できる言語 (Julia, Python, R等) を利用すること\n授業ではコード例としてJuliaを利用するため, Juliaを利用することを推奨\n第1回TAセッションでJuliaの基本的な使い方を解説する\n\nレポートについて\n\nPDF形式で提出. タイプされたもののみ. 手書きは不可\n\nレポートにコードは含めないこと\n図と表以外のコード実行のアウトプットも含めてはいけない\nTAのPC上でコンパイルすることから, Quartoでは有料のフォント (特にMacのヒラギノ) は利用しないこと.\n\nQuarto での作成を推奨する. \\(\\LaTeX\\) 等でレポートを作成した場合は, レポート用のコードの提出は必要ない\n\nQuarto (Julia) の場合 → PDFレポートとqmdファイルの提出\nPython + \\(\\LaTeX\\) の場合 → PDFレポートとpyファイルの提出\n\nQuartoを用いない場合は main 関数を定義し, TAが main 関数を実行することのみでレポートで用いる画像や数値が再現できるようにすること\n第1回のTAセッションでQuartoの基本的な使い方を解説する\n解答には以下のテンプレートを利用してもよい\n\n Template   Exercise 0"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html",
    "href": "lecture/01-2-numerical-method.html",
    "title": "数値計算の基礎",
    "section": "",
    "text": "using Plots\nusing LaTeXStrings\nusing Roots\nusing NonlinearSolve\nusing FastGaussQuadrature\nusing Distributions\nusing SummaryTables\nusing BenchmarkTools\nusing JuMP\nimport Ipopt\n\nimport Random\nRandom.seed!(1234)\ndefault(size=(500, 309), titlefontsize=10, fmt=:svg)"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#一階条件の数値解法",
    "href": "lecture/01-2-numerical-method.html#一階条件の数値解法",
    "title": "数値計算の基礎",
    "section": "一階条件の数値解法",
    "text": "一階条件の数値解法\nモデルを解くためには, 一階条件を解く必要があります. 特殊なケースや対数線形化などの場合を除き, 多くの場合の一階条件は非線形方程式となります. 非線形方程式の数値解法は, 一変数の場合と多変数の場合に分けられます.\n\n一変数の非線形方程式\nモデルを解く最初のステップとして, まずは意思決定者の最適化問題を解くことが挙げられます. 例えば以下の最適化問題を考えてみましょう.\n\\[\n\\max_{c, l} \\frac{c^{1-\\gamma_c}}{1-\\gamma_c} + \\alpha_l \\frac{l^{1-\\gamma_l}}{1-\\gamma_l} \\quad \\text{s.t.} \\quad c = w (1-l)\n\\tag{1}\\]\nこの問題は以下の一階条件の解を求めることで解くことができます.\n\\[\nw^{1-\\gamma_c} (1-l)^{-\\gamma_c} - \\alpha_l l^{-\\gamma_l} = 0.\n\\]\n\nfoc(l; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5) =\n    w^(1 - γ_c) * (1 - l)^(-γ_c) - α_l * l^(-γ_l)\n\n\n\nCode\nplot(0.1:0.01:0.9, foc, label=L\"w^{1-\\gamma_c} (1-l)^{-\\gamma_c} - \\alpha_l l^{\\gamma_l}\", lw=2)\nhline!([0.0], ls=:dash, lw=2, label=false)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: FOC for CRRA utility\n\n\n\n\nこれは, 一般に解析解がありません (\\(\\gamma_c = \\gamma_l = 1\\)などを除く.) そのため, 数値計算を用いて解く必要があります. この様な一変数の非線形方程式 \\(f(x) = 0\\) の解法として, 以下の2つの選択肢があります.\n\nNon-bracketing method: 初期値 \\(x_0\\) からスタートして, \\(f(x_n)\\) が十分0に近づくまで反復的に計算. (ニュートン法など)\nBracketing method: 区間 \\([a, b]\\) を選び, 区間を狭めていくことで解を求める. (二分法など)\n\n一般に, Non-bracketing method は収束が速い代わりにその収束は保証されません. 一方で, Bracketing method は収束がわずかに遅い代わりに, 解が存在する区間を保証することができます. 以下では, その理由とそれぞれの適した利用場面を解説します.\n\nNon-bracketing method\nNon-bracketing method は基本的には一階微分を利用し, 初期値 \\(x_0\\) からスタートして反復的に解を求めます. ここでは, 最も古典的で簡単なニュートン法を紹介します.\n\n\n\n\n\n\nTipニュートン法\n\n\n\n\n初期値 \\(x_0\\) を選ぶ. また停止条件として十分小さい \\(\\epsilon &gt; 0\\) を選ぶ.\n\\(x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\\) を計算する.\n\\(|f(x_{n+1})| &lt; \\epsilon\\) ならば停止し, \\(x_{n+1}\\) を解として返す. そうでなければ, \\(n \\leftarrow n+1\\) として2に戻る.\n\n\n\n\n\n\n\n\n\nFigure 2: Visualization of Newton Method\n\n\n\n\ndfoc(l; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5) =\n    w^(1 - γ_c) * γ_c * (1 - l)^(-γ_c - 1) + α_l * γ_l * l^(-γ_l - 1)\n\nfind_zero((foc, dfoc), 0.5, Roots.Newton())\n\n0.530349570343484\n\n\nHybrid method\nJuliaのRoots.jlのデフォルトのNon-bracketing method (Order0())は, 厳密にはBracketing methodも一部利用します. また一階微分も必要としないため, より汎用的に利用することができます. ただし, 収束が速く収束が保証されない性質はNon-bracketing methodと同じです.\n\nl = find_zero(foc, 0.5)\n\n0.530349570343484\n\n\n定義域の変換\nNon-bracketing method では, \\(x_{n+1}\\) の値を更新する際に, 必ずしも \\(x_{n+1}\\) が定義域内にあることが保証されません. 例えば, 今回の例では 余暇時間ですので, \\(l \\in (0, 1)\\) ですが, 初期値や関数形によっては, \\(l &lt; 0\\) や \\(l &gt; 1\\) となる可能性があります.\nこの場合, 端点解が存在するかどうかを確認する必要があります. 端点解が想定される場合は, 次節で説明するように Bracketing method を利用することが適しています. 今回の例では, 端点解が存在しないため (\\(l = 0, 1\\) のどちらにおいても効用が負の無限大に発散するため), Non-bracketing method での解の収束が保証されています. 以下の様な定義域の変換を用いることで, 解の収束を保証することができます.\n\n\n\n\n\n\nNote定義域の変換\n\n\n\n\\(x\\) が区間 \\((a, b)\\) で定義されるとき, 以下の変換を用いて定義域を \\((-\\infty, \\infty)\\) にすることができる.\n\\[\nx = \\frac{a + b \\exp y}{1 + \\exp y}\n\\]\n明らかに, \\(y \\rightarrow -\\infty\\) のとき \\(x \\rightarrow a\\), \\(y \\rightarrow \\infty\\) のとき \\(x \\rightarrow b\\) となる.\n\n\n今回の例では, \\(l = \\frac{1}{1 + \\exp(y)}\\) (つまりシグモイド関数) という変換を用いることができます.\n\ny = find_zero(y -&gt; foc(1 / (1 + exp(y))), 0.0)\nl = 1 / (1 + exp(y))\n\n0.530349570343484\n\n\n\n\nBracketing method\nBracketing method は, 解が存在する区間 \\([a, b]\\) を選び, その区間を狭めていくことで解を求めます. ここでは最も基本的な二分法を用いることで解を求めることができます.\n\n\n\n\n\n\nTip二分法\n\n\n\n\n区間 \\([a, b]\\) を選ぶ. また停止条件として十分小さい \\(\\epsilon &gt; 0\\) を選ぶ.\n\\(f(a) \\cdot f(b) &lt; 0\\) ならば, \\(c = \\frac{a + b}{2}\\) を計算する.\n\\(|f(c)| &lt; \\epsilon\\) ならば, \\(c\\) を解として返す. そうでなければ, \\(f(a) \\cdot f(c) &lt; 0\\) ならば, \\(b \\leftarrow c\\) として2に戻る. そうでなければ, \\(a \\leftarrow c\\) として2に戻る.\n\n\n\n\n\n\n\n\n\nFigure 3: Visualization of Bisection Method\n\n\n\n例えば, 今回の例では \\(l \\in (0, 1)\\) ですので, \\(l = 0\\) と \\(l = 1\\) で効用が発散することから, 解が存在する区間は \\((0, 1)\\) です. なお, 端点でFOCが定義されてない場合も多いので, 端点より微小に内側の区間を選ぶことが多いです.\n\nϵ = 1e-9\nl = find_zero(foc, (ϵ, 1 - ϵ))\n\n0.530349570343484\n\n\n端点解の存在\n以下の様なカップルの意思決定問題を考えてみましょう.\n\\[\n\\max_{c_m, c_f, l_m, l_f} u(c_m, l_m) + u(c_f, l_f)\n\\tag{2}\\]\nsubject to\n\\[\nc_m + c_f = w_m (1 - l_m) + w_f (1 - l_f).\n\\]\n一階条件から以下の関係が導けます:\n\\[\n\\frac{l_m}{l_f} = \\left(\\frac{w_f}{w_m}\\right)^{\\frac{1}{\\gamma_l}}.\n\\]\nこの関係から一方の相対賃金が十分に大きい場合, 例えば \\(w_m \\gg w_f\\) の場合, \\(l_f &gt; 1\\) となる可能性があります (\\(l_m\\) は余暇時間のため, 0よりある程度大きい値をとるということが想像できます.) 内点解が存在する場合の \\(l_f\\) に関する一階条件は以下のようになります.\n\\[\nw_m\\left(1-\\left(\\frac{w_f}{w_m}\\right)^{\\frac{1}{\\gamma_l}}l_f\\right) + w_f(1-l_f) - 2\\left(\\frac{w_f}{\\alpha_l}\\right)^{\\frac{1}{\\gamma_c}}l_f^{\\frac{\\gamma_l}{\\gamma_c}} = 0.\n\\]\n\n\nCode\nfunction foc_bargaining(l_f; w_m=1.0, w_f=0.5, γ_c=1.5, α_l=1.2, γ_l=1.5)\n    return w_m * (1 - (w_f / w_m)^(1 / γ_l) * l_f) + w_f * (1 - l_f) -\n           2 * (w_f / α_l)^(1 / γ_c) * l_f^(γ_l / γ_c)\nend\n\nlf_grid = 0.01:0.01:0.99\nplot(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=1.0), label=L\"w_f = 1.0\", xlabel=L\"l_f\")\nplot!(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=0.5), label=L\"w_f = 0.5\")\nplot!(lf_grid, l_f -&gt; foc_bargaining(l_f, w_f=0.1), label=L\"w_f = 0.1\")\nhline!([0.0], ls=:dash, lw=2, label=false, color=:black)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: FOC for bargaining problem. \\(w_m = 1.0\\), \\(\\alpha_l = 1.2\\), \\(\\gamma_c = \\gamma_l = 1.5\\).\n\n\n\n\nまた, \\(l_f = 1\\) における一階条件は以下のようになります.\n\\[\nw_m(1-l_m) - 2\\left(\\frac{w_m}{\\alpha_l}\\right)^{\\frac{1}{\\gamma_c}} l_m^{\\frac{\\gamma_l}{\\gamma_c}} = 0.\n\\]\nこの様な場合, Bracketing method の考えが有効です.\n\n端点 \\(l_m = 0, 1\\) (実用上は \\(\\epsilon, 1-\\epsilon\\)) において, 一階条件の値を計算.\n一階条件の値が異符号であれば, 二分法を用いて解を求める.\n一階条件の値が同符号であれば, 端点解 (この場合, \\(l_f = 1\\)) 上の解を求める.\n\n\nfunction solve_bargaining(; w_m=1.0, w_f=0.5, γ_c=1.5, α_l=1.2, γ_l=1.5)\n\n    ϵ = 1e-9\n    left = w_m * (1 - (w_f / w_m)^(1 / γ_l) * ϵ) + w_f * (1 - ϵ) -\n           2 * (w_f / α_l)^(1 / γ_c) * ϵ^(γ_l / γ_c)\n    right = w_m * (1 - (w_f / w_m)^(1 / γ_l) * (1 - ϵ)) + w_f * ϵ -\n            2 * (w_f / α_l)^(1 / γ_c) * (1 - ϵ)^(γ_l / γ_c)\n\n    if left * right &lt; 0\n        l_f = find_zero(\n            l_f -&gt; w_m * (1 - (w_f / w_m)^(1 / γ_l) * l_f) + w_f * (1 - l_f) -\n                   2 * (w_f / α_l)^(1 / γ_c) * l_f^(γ_l / γ_c),\n            (ϵ, 1 - ϵ))\n        l_m = (w_f / w_m)^(1 / γ_l) * l_f\n    else\n        l_f = 1.0\n        x = find_zero(\n            x -&gt; w_m * (1 - 1 / (1 + exp(x))) -\n                 2 * (w_m / α_l)^(1 / γ_c) * (1 / (1 + exp(x)))^(γ_l / γ_c),\n            0.0)\n        l_m = 1 / (1 + exp(x))\n    end\n\n    c = w_m * (1 - l_m) + w_f * (1 - l_f)\n    c_m = 0.5 * c\n    c_f = 0.5 * c\n    U = (c_m^(1 - γ_c) / (1 - γ_c)) + α_l * (l_m^(1 - γ_l) / (1 - γ_l)) +\n        (c_f^(1 - γ_c) / (1 - γ_c)) + α_l * (l_f^(1 - γ_l) / (1 - γ_l))\n    return (c_m=c_m, c_f=c_f, l_m=l_m, l_f=l_f, U=U)\nend\n\n\n\nCode\nplot(0.1:0.01:0.9, w_f -&gt; solve_bargaining(w_f=w_f).l_m, label=L\"l_m\", xlabel=L\"w_f\")\nplot!(0.1:0.01:0.9, w_f -&gt; solve_bargaining(w_f=w_f).l_f, label=L\"l_f\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Solution of bargaining problem. \\(w_m = 1.0, \\alpha_l = 1.2, \\gamma_c = \\gamma_l = 1.5\\).\n\n\n\n\n\n\n\n多変数の非線形方程式\n多変数の非線形方程式では Bracketing method は使えず, ニュートン法のような Non-bracketing method を用いる必要があります. そのため内点解と微分可能な関数を仮定しており, 端点解やスムースでない関数が想定される場合は使えません. そのような場合は, 原始的なグリッドサーチを用いるか, 後述するのように非線形最適化問題として解く必要があります.\nなお, 多くの標準的な効用関数 (CRRA, CESなど) の場合, 一階条件は一変数の非線形方程式に帰着できます. 今回は学習のために, 式 1 を3変数 (\\(c\\), \\(l\\), \\(\\lambda\\)) の非線形方程式として解いてみましょう. NonlinearSolve.jl を用いると便利です.\n\\[\n\\begin{aligned}\nc^{-\\gamma_c} &= \\lambda \\\\\n\\alpha_l l^{-\\gamma_l} &= \\lambda w \\\\\nc &= w(1-l)\n\\end{aligned}\n\\]\n\nfunction solve_nonlinear_system(; w=1.0, γ_c=1.5, α_l=1.2, γ_l=1.5)\n    f((c, l, λ), par) = [\n        λ * c^γ_c - 1,\n        α_l - λ * w * l^γ_l,\n        c - w * (1 - l)\n    ]\n    prob = NonlinearProblem(f, [0.5, 0.5, 0.35], 0.)\n    sol = solve(prob, NewtonRaphson())\n\n    return (c=sol.u[1], l=sol.u[2], λ=sol.u[3])\nend\n\nsolve_nonlinear_system()\n\n(c = 0.469650429656516, l = 0.530349570343484, λ = 3.1069761107915044)\n\n\n工夫として負の指数を避けるように式変形しています. これは最適化の際に, 負の数の負の数乗によってエラーが起きることを避けるためです.\n\n\nMathematical Programming\nより強力な方法として, 解きたい最適化問題を直接ソルバーにかける方法があります. Juliaの場合は JuMP.jl が有名です. ここでは, 式 2 を JuMP を用いて解いてみましょう.a\n\nfunction solve_jump(; w_m=1.0, w_f=0.5, γ_c=1.5, α_l=1.2, γ_l=1.5)\n\n    model = Model(Ipopt.Optimizer)\n    set_silent(model)\n    set_attribute(model, \"print_level\", 0)\n\n    @variables(model, begin\n        0 &lt;= c_m\n        0 &lt;= c_f\n        0 &lt;= l_m &lt;= 1\n        0 &lt;= l_f &lt;= 1\n    end)\n\n    @objective(\n        model,\n        Max,\n        (c_m^(1 - γ_c) / (1 - γ_c)) + α_l * (l_m^(1 - γ_l) / (1 - γ_l)) +\n        (c_f^(1 - γ_c) / (1 - γ_c)) + α_l * (l_f^(1 - γ_l) / (1 - γ_l))\n    )\n\n    @constraint(model, c_m + c_f == w_m * (1 - l_m) + w_f * (1 - l_f))\n\n    optimize!(model)\n\n    return (\n        c_m=value(c_m),\n        c_f=value(c_f),\n        l_m=value(l_m),\n        l_f=value(l_f),\n        U=objective_value(model)\n    )\nend\n\n図 5 と同じ結果が得られました.\n\n\nCode\nplot(0.1:0.01:0.9, w_f -&gt; solve_jump(w_f=w_f).l_m, label=L\"l_m\", xlabel=L\"w_f\")\nplot!(0.1:0.01:0.9, w_f -&gt; solve_jump(w_f=w_f).l_f, label=L\"l_f\")\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Solution of bargaining problem by JuMP. \\(w_m = 1.0, \\alpha_l = 1.2, \\gamma_c = \\gamma_l = 1.5\\).\n\n\n\n\nとても便利に思えますが, いくつか注意点があります.\n\n計算の正しさが保証されない. アルゴリズムの中身がブラックボックスであり, 研究者自身が解の正しさを保証できない. 端点解を見逃す可能性や収束しない可能性がある.\n計算が遅い. 一階条件を直接解く場合と比べると, 問題の複雑さが増すため, 計算が遅くなる. より大規模なモデルを解きたい場合には, 致命的な問題となる可能性がある.\n\n\n@benchmark solve_bargaining(w_f=0.1)\n\n\nBenchmarkTools.Trial: 10000 samples with 160 evaluations per sample.\n Range (min … max):  660.938 ns …  1.425 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     662.500 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   664.906 ns ± 13.937 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▄█▇▄                       ▂  ▁                              ▁\n  ████▇▇▆▄▅▅▅▄▄▅▅▄▅▇▇▆▆▄▅▁▄▆█████▅▃▆▅▅▅▆▇▅▅▅▄▅▅▅▆▅▅▆▅▅▃▅▄▃▅▆▅▆ █\n  661 ns        Histogram: log(frequency) by time       708 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\n\n\n@benchmark solve_jump(w_f=0.1)\n\n\nBenchmarkTools.Trial: 4737 samples with 1 evaluation per sample.\n Range (min … max):  983.125 μs … 216.753 ms  ┊ GC (min … max): 0.00% … 13.95%\n Time  (median):       1.003 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):     1.054 ms ±   3.135 ms  ┊ GC (mean ± σ):  0.61% ±  0.20%\n\n     ▅▇▇█▆▅▅▄▄▂▁                                                 \n  ▂▄█████████████▇▆▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▁▁▂ ▄\n  983 μs           Histogram: frequency by time         1.12 ms &lt;\n\n Memory estimate: 111.91 KiB, allocs estimate: 3816.\n\n\n\nJuMPを用いた方法がかなり遅いことが分かります.1 そのため, 私自身は検算目的で使う場合がほとんどです."
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#数値積分",
    "href": "lecture/01-2-numerical-method.html#数値積分",
    "title": "数値計算の基礎",
    "section": "数値積分",
    "text": "数値積分\n以下の定積分を \\(n\\) 個の区間に分割して近似的に計算することを考えます.\n\\[\n\\int_{a}^{b} f(x) \\,dx \\simeq \\sum_{i=1}^{n} w_i f(x_i)\n\\]\nここで, \\(w_i\\) は各区間の重み, \\(x_i\\) は各区間の評価点です. この形の積分計算はいくつか方法がありますが, 最も基本的な台形則と精度の高いガウス求積を紹介します.\n\n台形則 (Trapezoidal Rule)\n\n\n\n\n\n\nTip台形則 (Trapezoidal Rule)\n\n\n\n\n区間 \\([a, b]\\) を \\(n\\) 個の等間隔の区間に分割する. つまり, \\(x_i = a + i \\cdot \\frac{b - a}{n}\\) とする.\n各区間を台形で近似する. よって近似式は以下のようになる.\n\n\\[\n\\int_{a}^{b} f(x) \\,dx \\simeq \\sum_{i=1}^{n} (x_i - x_{i-1}) \\frac{f(x_{i-1}) + f(x_i)}{2}\n\\]\n\n\n\n\n\n\n\n\nFigure 7: Vizualization of Trapezoidal Rule\n\n\n\nここでは, \\(f(x) = \\sqrt{1 - x^2}\\) の \\([0, 1]\\) での積分を計算してみましょう. 単位円の1/4の面積であるため, 解析解は \\(\\pi / 4\\) です.\n\nfunction trapezoid_rule(f, a, b, n)\n    xs = range(a, b, length=n)\n    return sum((xs[i] - xs[i-1]) * (f(xs[i-1]) + f(xs[i])) / 2 for i in 2:n)\nend\n\nsol_tr100 = trapezoid_rule(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 100)\nsol_tr1000 = trapezoid_rule(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 1000)\n\nπ / 4, sol_tr100, sol_tr1000\n\n(0.7853981633974483, 0.7850997945286542, 0.7853888527655861)\n\n\n100個の評価点で少数第三位まで, 1000個の評価点で少数第四位までの精度が得られていることがわかります.\n\n\nガウス求積 (Gaussian Quadrature)\n\n\n\n\n\n\nNoteガウス求積 (Gaussian Quadrature)\n\n\n\n\\(n\\) 次のルジャンドル多項式 \\(P_n(x)\\) の零点を \\(x_1, \\dots, x_n\\) とし, \\(L_i(x) = \\prod_{j \\neq i} (x - x_j)\\), \\(w_i = \\int_{-1}^{1} \\frac{L_i(x)}{L_i(x_i)} \\,dx\\) とすると,\n\\[\n\\int_{-1}^{1} f(x) \\,dx = \\sum_{i=1}^{n} w_i f(x_i)\n\\]\nが任意の \\(2n-1\\) 次の多項式 \\(f(x)\\) において成り立つ.\n\n\nこの方法は近似値ではなく, \\(2n-1\\) 次の多項式に対して厳密な値を計算することができるという点で強力です. また, \\(f(x)\\) が \\(2n-1\\) 次の多項式で十分近似できる場合, 精度の高い計算が可能です.\n\n\n\n\n\n\nTip定義域の変換 (ガウス求積)\n\n\n\nFastGaussQuadrature.jl 等のパッケージを利用する際には, 定義域を \\([-1, 1]\\) に変換する必要がある. \\(x = \\frac{b-a}{2} z + \\frac{a+b}{2}\\) と変換すると\n\\[\n\\int_{a}^b f(x) \\,dx = \\frac{b - a}{2} \\int_{-1}^1 f\\left(\\frac{b - a}{2} z + \\frac{a + b}{2}\\right) \\,dz\n\\]\nを得られる.\n\n\n\nfunction gaussian_quadrature(f, a, b, n)\n    z, w = gausslegendre(n)\n    return (b - a) / 2 * sum(w .* f.((b - a) / 2 * z .+ (a + b) / 2))\nend\n\nsol_gl10 = gaussian_quadrature(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 10)\nsol_gl100 = gaussian_quadrature(x -&gt; sqrt(1 - x^2), 0.0, 1.0, 100)\n\nπ / 4, sol_gl10, sol_gl100\n\n(0.7853981633974483, 0.7855247925013235, 0.7853983068468604)\n\n\n10個程度の評価点で少数第三位まで, 100個程度の評価点で少数第六位までの精度が得られていることがわかります.\n\nガウスエルミート求積\nガウス求積は上に挙げたガウス・ルジャンドル求積の他にも, ガウス・エルミート求積などの類似系があります.\n\n\n\n\n\n\nNoteガウス・エルミート求積 (Gaussian-Hermite Quadrature)\n\n\n\n\\(n\\) 次のエルミート多項式 \\(H_n(x)\\) の零点を \\(x_1, \\dots, x_n\\) とし, \\(w_i = \\frac{2^{n-1} n! \\sqrt{\\pi}}{\\left(n H_{n-1}(x_i)\\right)^2}\\) とすると,\n\\[\n\\int_{-\\infty}^{\\infty} f(x) e^{-x^2} \\,dx \\simeq \\sum_{i=1}^{n} w_i f(x_i)\n\\]\n\n\n被積分関数が \\(e^{-x^2}\\) という部分を持つ場合により高精度に計算することができます. 具体的には, 正規分布に基づく積分の計算などに利用可能です. ここで, 式 1 によって意思決定する人々の時間給 \\(w\\) が次のような分布に従っているとします.\n\\[\n\\log w \\sim \\mathcal{N}(\\mu, \\sigma).\n\\]\nこの時, 平均労働時間を積分によって求めてみましょう.\n\\[\n\\overline{h} = \\int_{0}^{\\infty} h^*(w) \\,dF(w; \\mu, \\sigma).\n\\]\nここで, \\(h^*(w)\\) は時給 \\(w\\) の下での最適労働時間, \\(F(w; \\mu, \\sigma)\\) は \\(w\\) の累積分布関数です. ここで \\(F(w; \\mu, \\sigma)\\) が対数正規分布であることを利用して, ガウス・エルミート求積を用いて計算します.\n\\[\n\\begin{aligned}\n\\overline{h} &= \\int_{-\\infty}^{\\infty} h^*(\\exp(y)) \\,d\\Phi(y; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} h^*(\\exp(y)) \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left(-\\frac{(y - \\mu)^2}{2\\sigma^2}\\right) \\,dy \\\\\n&=\\int_{-\\infty}^{\\infty} h^*\\left(\\exp\\left(\\sqrt{2}\\sigma z + \\mu\\right)\\right) \\frac{1}{\\sqrt{\\pi}} \\exp\\left(-z^2\\right) \\,dz \\\\\n&\\simeq \\sum_{i=1}^{n} w_i h^*\\left(\\exp\\left(\\sqrt{2}\\sigma x_i + \\mu\\right)\\right) \\frac{1}{\\sqrt{\\pi}}.\n\\end{aligned}\n\\]\nここでは \\(w = \\exp(y)\\), \\(y = \\sqrt{2}\\sigma z + \\mu\\) とした.\n\nfunction hours_worked(w; γ_c=1.5, α_l=1.2, γ_l=1.5)\n    y::Float64 = find_zero(y -&gt; foc(1 / (1 + exp(y)), w=w, γ_c=γ_c, α_l=α_l, γ_l=γ_l), 0.0)\n    l = 1 / (1 + exp(y))\n    return 1 - l\nend\n\nfunction mean_hours(; γ_c=1.5, α_l=1.2, γ_l=1.5, μ=0.0, σ=0.5, n=10)\n    x, w = gausshermite(n)\n    return sum(w .* hours_worked.(exp.(sqrt(2) * σ * x .+ μ), γ_c=γ_c, α_l=α_l, γ_l=γ_l) / sqrt(π))\nend\n\nmean_hours()\n\n0.4698575689662558\n\n\n\n\n\nモンテカルロ法\n期待値を求める積分の場合, モンテカルロ法による近似も有効です. 速度は遅いですが, 実装が簡単であり, ガウス求積などの方法による積分の検算などにも利用できます.\n\nmc_hours(; γ_c=1.5, α_l=1.2, γ_l=1.5, μ=0.0, σ=0.5, n=10^6) = mean(\n    hours_worked(rand(LogNormal(μ, σ)), γ_c=γ_c, α_l=α_l, γ_l=γ_l)\n    for _ in 1:n\n)\n\nmc_hours()\n\n0.46987292630609967"
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#非線形最適化",
    "href": "lecture/01-2-numerical-method.html#非線形最適化",
    "title": "数値計算の基礎",
    "section": "非線形最適化",
    "text": "非線形最適化\n\n非線形最適化問題の解法\n\n非線形最適化問題\n非線形最適化問題は, 一般に以下のような形で表されます.\n\\[\n\\min_{\\mathbf{x} \\in \\mathbb{R}^n} f(\\mathbf{x}).\n\\]\nこの時, \\(f(\\mathbf{x})\\) を目的関数といいます. この時, \\(\\mathbf{x}\\) に制約条件がある場合があります.\n1. 境界制約 (Bound constraints, Box constraints)\n\\[\nlb_{i} \\le x_{i} \\le ub_{i}, \\quad i = 1, \\dots, n.\n\\]\n2. 不等式制約 (Inequality constraints)\n\\[\nc_i(x_i) \\le 0, \\quad i = 1, \\dots, n.\n\\]\n3. 等式制約 (Equality constraints)\n\\[\nh_i(x_i) = 0, \\quad i = 1, \\dots, n.\n\\]\n制約付き最適化問題を扱えるかどうか, どの種類の制約まで扱えるかはアルゴリズムによって異なります.\n\n\n最適化アルゴリズム\n最適化アルゴリズムは日々進化しており, 様々なアルゴリズムが提案されています. どのアルゴリズムを用いるべきかは, 一般に判断が難しく, いくつかのアルゴリズムを実際に試してみる必要があります. ここでは, アルゴリズムを選ぶ際の概ねの考え方を紹介します. 詳細な解説は, 後に紹介する Nlopt パッケージのドキュメント を参照にしてください.\nGlobal vs. Local Method\n基本的に非線形最適化の数値計算では局所解しか求められません (\\(\\mathbb{R}^n\\) の全体を探索することはできないため). しかし, 数値計算の文脈では以下の意味で Global Method と Local Method に分けることができます.\n\nGlobal Method: Box constraints の中で満遍なく探索した場合, 最適である\nLocal Method: 初期値からの探索の結果, 最適である\n\nこの意味で, NLopt では GN_DIRECT や GN_ISRES などのいくつかのアルゴリズムが Global Method に分類されます. しかし, これらのアルゴリズムは計算時間が長く, 特に次元数の多い場合は計算が (現実的な研究時間の範囲で) 終了しない場合があります. そのため, これらの Global Method を用いる場合は, 評価回数や評価時間を制限してある程度の精度で計算を終了する必要があります. また, ここで求められた値を初期値として Local Method を用いることでより精度の高い解を求めることができます.\nGradient-based vs. Derivative-free Method\n最適化アルゴリズムは, 一階微分を用いるものと用いないものに分けることができます. 一階微分が事前に分かっている場合, 自動微分などで計算できる場合は, 一階微分を用いる方が計算が速く, 精度も高いです. これまで見てきたニュートン法などもこれに該当します. しかし, 複雑な問題では一階微分を計算することが困難な場合があります. その場合, Derivative-free なアルゴリズムを用いる必要があります.\nJuliaのパッケージ\nJuliaでよく使われる Optim.jl というパッケージでは, Gradient-based な local method として BFGS (ニュートン法の一種) がよく用いられており, Derivative-free な local method として Nelder-Mead がよく用いられています. さらに複雑なアルゴリズムを扱う場合は, NLopt.jl というパッケージを用いることが多いです. 数多くの最適化手法が Global, Local, Gradient-based, Derivative-free 満遍なく実装されており, それぞれのアルゴリズムを選ぶことができます. また, NLopt 自体はC++, Python, Rなどでも利用可能なライブラリです.\n私は簡単な最適化の場合は Optim.jl を用い, 複雑な最適化 (特に後述するSMM) の場合は NLopt.jl を用いることが多いです.\n\n\nOptimization.jl\nOptimization.jl は, 多くの最適化パッケージを統一的に扱うために作成されたパッケージです. すでに紹介した Optim.jl や NLopt.jl などのパッケージを同じ文法で扱うことができるため, 様々な最適化アルゴリズムを試す際に便利です.\n今回は, NLopt.jl と Optim.jl の両方を用いて, Rosenbrock 関数の最適化を行ってみます.\n\n\n\n\n\n\nNoteRosenbrock 関数\n\n\n\n\\(\\mathbf{x} = (x_1, \\dots, x_n)' \\in \\mathbb{R}^n\\) に対して,\n\\[\nf(x_1, \\dots, x_n) = \\sum_{i=1}^{n-1} \\left(100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\\right).\n\\]\n\n\nRosenbrock 関数は, 凸性がないため, 最適化アルゴリズムの性能を比較するために用いられることが多いです. また, 解として \\(f(1, \\dots, 1) = 0\\) が知られています. 2変数の場合, 以下のような形になります.\n\nrosenbrock(x, y) = (1 - x)^2 + 100 * (y - x^2)^2\n\n\n\nCode\nx_grid = -2:0.01:2\ny_grid = -1:0.01:3\n\np1 = contour(x_grid, y_grid, (x, y) -&gt; log1p(rosenbrock(x, y)), xlabel=L\"x\", ylabel=L\"y\", label=false)\np2 = surface(x_grid, y_grid, (x, y) -&gt; log1p(rosenbrock(x, y)), xlabel=L\"x\", ylabel=L\"y\", label=false)\n\nplot(p1, p2, layout=(1, 2), size=(800, 400))\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Rosenbrock function. Z-axis is log plus one of Rosenbrock function.\n\n\n\n\nこれをOptimization.jlを用いて解いてみましょう. まずは, Optim.jl のNelder-Mead法を用いて解いてみます.\n\nusing Optimization\nusing OptimizationOptimJL\n\nprob = OptimizationProblem((x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.])\nsol = solve(prob, NelderMead())\n\nretcode: Success\nu: 2-element Vector{Float64}:\n 0.9999634355313174\n 0.9999315506115275\n\n\nOptimization.jl のやや癖のあるところは, \\(f(\\mathbf{x}, \\mathbf{p})\\) のように, パラメータ \\(\\mathbf{p}\\) を必ず与える必要があるところです. そのため, 匿名関数を用いて, \\(f(\\mathbf{x}, \\mathbf{p})\\) 型に変換しています.\n次に, NLopt.jl を用いて解いてみます. 今回は, local method の COBYLA (LN_COBYLA) を用いて解いてみます. これも, derivative-free なアルゴリズムです.\n\nusing OptimizationNLopt\n\nprob = OptimizationProblem((x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.])\nsol = solve(prob, NLopt.LN_COBYLA())\n\nretcode: Success\nu: 2-element Vector{Float64}:\n 0.9999999999996291\n 0.9999999999992569\n\n\n次に, NLopt.jl の global method の GN_DIRECT を用いて解いてみます. こちらは, 探索範囲を制限し, 評価回数を制限して計算を終了します.\n\nprob = OptimizationProblem(\n    (x, p) -&gt; rosenbrock(x[1], x[2]), [0., 0.], lb=[-2, -2], ub=[2, 3])\nsol = solve(prob, NLopt.GN_DIRECT(), maxiters=10000)\n\nretcode: MaxIters\nu: 2-element Vector{Float64}:\n 0.9999999999971578\n 0.9999999999943192\n\n\n\n\n\nSimulated Method of Moments (SMM)\nモデルのパラメータの決定方法には以下の3つの方法があります.\n\n先行研究のパラメータを用いる (\\(\\beta = 0.96\\), Prescott (1986) など)\nデータから回帰分析などを用いて直接推定する.\nモデルのシミュレーション結果とデータを比較し, それに合うようにパラメータを調整する (Simulated Method of Moments, SMM)\n\n2の方法は, モデルごとに設定した関数形の一階条件などから導かれる式にデータを代入することでパラメータを推定する方法です. モデルごとに工夫がなされているため, 今後の授業でモデルを学ぶ際に紹介します. また1の方法で用いられるパラメータも先行研究において, 2の方法で推定された値を用いていることが多いです.\nこの節では, 3の方法であるSMMの概略を紹介します. 今後の授業で扱うモデルでもほとんど共通の方法が用いられています.\n\n\n\n\n\n\nNoteSimulated Method of Moments (SMM)\n\n\n\n\\(n\\) 次元のパラメータ \\(\\theta\\) を推定するとする. \\(\\theta\\) を代入した際にモデル (のシミュレーション) によって得られる \\(m \\ge n\\) 次元のモーメントを \\(\\mathcal{M}(\\theta)\\) とする. また, データから得られる同様のモーメントを \\(\\text{Data}\\) とする. 任意の対称重み行列 \\(W\\) を用いて, 以下の最適化問題を解く.\n\\[\n\\hat{\\theta} = \\arg\\min_{\\theta} \\left(\\mathcal{M}(\\theta) - \\text{Data}\\right)' W \\left(\\mathcal{M}(\\theta) - \\text{Data}\\right)\n\\]\n\n\nここで, 重み行列 \\(W\\) は, 単位行列, \\(\\text{diag}(\\text{Data})\\), \\(\\text{diag}(\\mathbb{V}(\\text{Data}))\\) を用いることが多いです. また推定値に対する標準誤差も計算すべきですが, 分散共分散行列の計算が必ずしも計算できない場合があるなど, かなり複雑な問題があります. 詳細は Cocci and Plagborg-Møller (2024) の議論を参照してください. 実際の論文では標準誤差を示さない場合も多いです.\n\nSMMの実践\nここでは, SMMを用いて労働供給のパラメータを推定する. かなり簡略化された例を用いるため, モデルの当てはまりは悪いが, SMMの考え方を理解するための例として利用する.\nモデル\n\\[\n\\max_{c, l} u(c, l) = \\log c + \\alpha \\log (1-l) \\quad \\text{s.t.} \\quad c = w (1 - l)\n\\]\n\n\\(c\\): 消費\n\\(w\\): 時給\n\\(l\\): 余暇時間\n\n時給 \\(w\\) は以下のような分布に従うとする.\n\\[\n\\log w \\sim \\mathcal{N}(\\mu, \\sigma).\n\\]\n標準化のため, \\(\\mu = 0\\) とする. この時, \\(\\theta = (\\alpha, \\sigma)\\) を推定する.\nデータ\nリクルートワークス研究所の 全国就業実態パネル調査 を用いる. なお, JPSED.stat から集計データをダウンロードすることができる. ここでは, 最新の2023年の20-29歳男性のデータを用いる.\n\n労働時間分布: 週あたりの労働時間 33.4時間\n\n週あたりの利用可能な労働時間は, \\(16 \\times 7 = 112\\) 時間とし, \\(1 - \\bar{l} = 1 - 33.4 / 112 \\simeq 0.7\\)\n\n所得分布: 主な仕事からの年収. 図 9.\n\n50万円未満は25万円, 50-100万円は75万円のように間の値を用い, 1200万円以上は1200万円とする\n対数所得の分散をターゲットとする\n\n\n\n\nCode\nmean_leisure_data = 1 - 33.4 / (16 * 7)\nearn = [25, 75, 150, 250, 350, 450, 550, 650, 750, 850, 950, 1100, 1200]\ndensity = [13.7, 12.2, 12.3, 14.8, 20.2, 16.3, 7.0, 2.0, 0.6, 0.4, 0.1, 0.3, 0.2] / 100\nmean_learn_data = density' * log.(earn)\nsd_learn_data = sqrt(density' * (log.(earn) .- mean_learn_data) .^ 2)\n\nplot(earn, density, label=\"Density\", xlabel=\"Earnings (10K JPY)\",\n    ylabel=\"Density\", lw=2, legend=false)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Distribution of earnings. Data from JPSED.stat. 20-29 aged men in 2023.\n\n\n\n\n一階条件から容易に \\(l = \\frac{\\alpha}{w + \\alpha}\\) となることがわかります. ガウス・エルミート求積を用いて, 労働時間の平均は以下のように計算できます.\n\\[\n\\begin{aligned}\n\\mathbb{E}[l] &= \\int_{-\\infty}^{\\infty} l(w) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\frac{\\alpha}{w + \\alpha} \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq \\sum_{i=1}^{n} \\xi_i \\frac{\\alpha}{\\exp\\left(\\sqrt{2}\\sigma x_i + \\mu\\right) + \\alpha} \\frac{1}{\\sqrt{\\pi}} \\\\\n\\end{aligned}\n\\]\nここで, \\(\\xi_i, x_i\\) はガウス・エルミート求積の重みと評価点です. 同様に, 対数収入 \\(\\log e\\) の平均と分散は以下のように計算できます.\n\\[\n\\begin{aligned}\n\\mathbb{E}[\\log e] &= \\int_{-\\infty}^{\\infty} \\log(w(1-l)) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\log\\left(\\frac{w^2}{\\alpha + w}\\right) \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} 2\\log w \\,dF(w; \\mu, \\sigma) - \\int_{-\\infty}^{\\infty} \\log (\\alpha + w) \\,dF(w; \\mu, \\sigma) \\\\\n&= 2\\mu - \\int_{-\\infty}^{\\infty} \\log (\\alpha + w) \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq 2\\mu - \\sum_{i} \\xi_i \\log\\left(\\alpha + \\exp(\\sqrt{2}\\sigma x_i + \\mu)\\right)\\frac{1}{\\sqrt{\\pi}}\\\\\n\\text{Var}(\\log e) &= \\int_{-\\infty}^{\\infty} \\left(\\log(w(1-l)) - \\overline{\\log e}\\right)^2 \\,dF(w; \\mu, \\sigma) \\\\\n&= \\int_{-\\infty}^{\\infty} \\left(2\\log w - \\log(\\alpha + w) - \\overline{\\log e}\\right)^2 \\,dF(w; \\mu, \\sigma) \\\\\n&\\simeq \\sum_{i}^{n} \\xi_i \\left(2(\\sqrt{2}\\sigma x_i + \\mu) - \\log\\left(\\alpha + \\exp(\\sqrt{2}\\sigma x_i + \\mu)\\right) - \\overline{\\log e}\\right)^2 \\frac{1}{\\sqrt{\\pi}}\\\\\n\\end{aligned}\n\\]\n\nfunction moment(α, σ; n_gh=10)\n    x, ξ = gausshermite(n_gh)\n    μ = 0.0\n    mean_leisure = ξ' * (α ./ (exp.(sqrt(2) * σ * x .+ μ) .+ α)) / sqrt(π)\n    mean_learn = 2μ - ξ' * log.(α .+ exp.(sqrt(2) * σ .* x .+ μ)) / sqrt(π)\n    sd_learn = sqrt(ξ' * (2 * (sqrt(2) * σ .* x .+ μ) - log.(α .+ exp.(sqrt(2) * σ .* x .+ μ)) .- mean_learn) .^ 2 / sqrt(π))\n\n    return [mean_leisure, sd_learn]\nend\n\nloss(α, σ; d=[mean_leisure_data, sd_learn_data]) = sqrt(sum(((moment(α, σ) .- d) ./ d) .^ 2))\nprob = OptimizationProblem((x, p) -&gt; loss(x[1], x[2]), [0.5, 0.5])\nsol = solve(prob, NelderMead()) # Optim.jl\nα, σ = sol.x\n\n2-element Vector{Float64}:\n 2.5167745032341324\n 0.5961675492466839\n\n\nなお, ほとんどの場合は3変数以上の最適化問題を解くため確認することができませんが, 2変数の場合はプロットにより損失関数の形状を確認することができます.\n\n\nCode\ncontour(0.01:0.01:5, 0.01:0.01:1, loss)\nscatter!([α], [σ], label=\"Solution\", markersize=5)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Contour plot of loss function.\n\n\n\n\nおそらく唯一の (局所) 解であることがわかります.\n\n\nCode\nmnt = moment(α, σ)\n\ndata = (\n    Parameter=[\"α\", \"σ\"],\n    Value=[α, σ],\n    Target=[\"Mean of Leisure Hours\", \"S.D. of Log Earnings\"],\n    Data=[mean_leisure_data, sd_learn_data],\n    Model=mnt\n)\n\nsimple_table(data)\n\n\n\n\nTable 1: Results of SMM\n\n\n\n\n    \n    \n    \n        Parameter\n        Value\n        Target\n        Data\n        Model\n    \n            \n        α\n        2.52\n        Mean of Leisure Hours\n        0.702\n        0.702\n    \n    \n        σ\n        0.596\n        S.D. of Log Earnings\n        1.02\n        1.02\n    \n    \n\n\n\n\n\n\n表 1 の結果から, モデルから得られたモーメントがデータのモーメントとほとんど一致していることがわかります. このモデルの当てはまりを確認するためにターゲットとしていないモーメントとして, 労働時間の分布を確認してみましょう. 推定された \\(\\alpha, \\sigma\\) の値を用いてモンテカルロシミュレーションを行い, 労働時間の分布を確認します. なお, 労働時間は \\(h^*(w) = 1 - \\frac{\\alpha}{w + \\alpha}\\) で計算でき, 週あたりの労働時間に直すために \\(h^*(w) \\times 16 \\times 7\\) を計算します.\n\n\nCode\nlbl_hours = [\"0-19\", \"20-34\", \"35-44\", \"45-59\", \"60+\"]\ndens_hours_data = [22.4, 12.1, 44.7, 17.9, 3.8] / 100\nhours_model = [(w / (w + α)) * 16 * 7 for w in rand(LogNormal(0, σ), 10^6)]\n\nbins = [0, 20, 35, 45, 60, 113]\ndens_hours_model = [mean(bins[i] .&lt;= hours_model .&lt; bins[i+1]) for i in 1:(length(bins)-1)]\n\nbar(lbl_hours, dens_hours_data, label=\"Model\")\nscatter!(lbl_hours, dens_hours_model, label=\"Data\", xlabel=\"Hours Worked per Week\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Distribution of hours worked.\n\n\n\n\n図 11 で分かるように, モデルの労働時間の分布はデータの労働時間の分布とかなり異なります. これは, モデルが単純化されすぎているためです. 例えば, 20-29歳の男性のデータを用いてるため, 学生や新卒の人々が多く含まれており, 労働時間が短くなっている可能性があります. また, 賃金に対する労働時間の弾力性 (フリッシュ弾力性) が重要な役割を果たしていると考えられるにもかかわらず, 対数型効用関数という柔軟性のない効用関数を用いていることに問題がある可能性があります. ターゲットとしたモーメントの当てはまりは定義から良いので, ターゲットとしていないモーメントによる評価も重要です."
  },
  {
    "objectID": "lecture/01-2-numerical-method.html#footnotes",
    "href": "lecture/01-2-numerical-method.html#footnotes",
    "title": "数値計算の基礎",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n実際には Parameter を導入するなどして, 計算を早くすることは可能ですが, それでも一階条件を直接解く方法よりは遅くなります.↩︎"
  },
  {
    "objectID": "lecture/10-1-julia-intro.html",
    "href": "lecture/10-1-julia-intro.html",
    "title": "Juliaの基礎",
    "section": "",
    "text": "数値計算をする上でプログラミング言語の選択はとても重要です. 経済学でよく使われるプログラミング言語は速度の意味で概ね以下のような関係があります.\n\\[\n\\text{C/C++, Fortran, Julia} \\gg \\text{Python, Matlab} &gt; \\text{R}\n\\]\n\n\n\n\n\n\nFigure 1: Julia Micro Benchmarks\n\n\n\nおおむね, C/C++, Fortran, Juliaは10-100倍ほどPython, Matlab, Rより速く計算が可能です. なおベクトル化というテクニックやPythonのNumbaを用いることで, Python, Matlab, Rでも同様の速度も出すことが可能ですが, C/C++, Fortran, Juliaなどの言語とはそもそも質的に異なるという事実は頭に入れておいた方が良いでしょう.\n\n\n\nJuliaはC並の速さとPython, Matlab, Rの使いやすさを目指して開発された比較的新しい言語です (Bezanson et al. 2012). 私自身, 高速化のためにはある程度の前提知識が必要なものの, C/C++, Fortranよりもデバックが容易であるため, 数値計算においてはJuliaを使っています.\nまた, 無料かつオープンソースであるため, アカデミアを離れたとしても使い続けることができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#なぜjuliaを使うのか",
    "href": "lecture/10-1-julia-intro.html#なぜjuliaを使うのか",
    "title": "Juliaの基礎",
    "section": "",
    "text": "数値計算をする上でプログラミング言語の選択はとても重要です. 経済学でよく使われるプログラミング言語は速度の意味で概ね以下のような関係があります.\n\\[\n\\text{C/C++, Fortran, Julia} \\gg \\text{Python, Matlab} &gt; \\text{R}\n\\]\n\n\n\n\n\n\nFigure 1: Julia Micro Benchmarks\n\n\n\nおおむね, C/C++, Fortran, Juliaは10-100倍ほどPython, Matlab, Rより速く計算が可能です. なおベクトル化というテクニックやPythonのNumbaを用いることで, Python, Matlab, Rでも同様の速度も出すことが可能ですが, C/C++, Fortran, Juliaなどの言語とはそもそも質的に異なるという事実は頭に入れておいた方が良いでしょう.\n\n\n\nJuliaはC並の速さとPython, Matlab, Rの使いやすさを目指して開発された比較的新しい言語です (Bezanson et al. 2012). 私自身, 高速化のためにはある程度の前提知識が必要なものの, C/C++, Fortranよりもデバックが容易であるため, 数値計算においてはJuliaを使っています.\nまた, 無料かつオープンソースであるため, アカデミアを離れたとしても使い続けることができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#環境構築",
    "href": "lecture/10-1-julia-intro.html#環境構築",
    "title": "Juliaの基礎",
    "section": "環境構築",
    "text": "環境構築\n\nJulia\nJuliaupを用いたインストールを推奨します.\nWindows\nパワーシェルを開き, 以下のコマンドを実行します.\nwinget install julia -s msstore\nMac, Linux\nターミナルを開き, 以下のコマンドを実行します.\ncurl -sSL https://julialang.org/juliaup | bash\nなお, インストール後はパワーシェル/ターミナルで以下のコマンドを実行することで最新版のJuliaにアップデートすることができます.\njuliaup update"
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#関数-forループ-if文",
    "href": "lecture/10-1-julia-intro.html#関数-forループ-if文",
    "title": "Juliaの基礎",
    "section": "関数, forループ, if文",
    "text": "関数, forループ, if文\n\n関数\nfunction f(K, L; α)\n    return K^α * L^(1 - α)\nend\n\nf(0.3, 0.7, α=0.5)\n\nfunctionとendで囲まれた部分が関数の定義です.\n引数は()内に,で区切って列挙します.\n引数のうち, ; 以降はキーワード引数と呼ばれ, 呼び出す際に引数名を用いる必要があります.\n\nfunction f(K, L, A=1.0; α)\n    return A * K^α * L^(1 - α)\nend\n\nf(0.3, 0.7, α=1/3) # or equivalently, f(0.3, 0.7, 1.0, α = 1/3)\n\n引数にデフォルトの値を持たせることができます.\nデフォルトの値をもつ引数は, デフォルトを持たない引数の後に配置する必要があります.\n\n一行関数\nf(x, y) = 2x + y^2 + x * y\nf(1.0, 2.0)\n\nfunction-endを省略し, =によって関数を定義することができます.\nなお, 変数の前の数値の*は省略可能です.\n\n\n\nforループ\n\nfor i in 1:5\n    println(i)\nend\n\n1\n2\n3\n4\n5\n\n\n\nfor-endで囲まれた部分がforループです.\ninの後にイテレータを指定します.\n\nfor i in 1:5\n    for j in 1:3\n        println((i, j))\n    end\nend\n\n# Or equivalently\nfor i in 1:5, j in 1:3\n    println((i, j))\nend\n\n2次元のforループを行う場合は, for-endをネストするか,で区切って複数のイテレータを指定します.\n\n\n\nif文\nfunction f(x)\n    if x &gt; 0\n        return \"Positive\"\n    elseif x &lt; 0\n        return \"Negative\"\n    else\n        return \"Zero\"\n    end\nend\n\nif-endで囲まれた部分がif文です.\nelseifやelseを用いて条件分岐を行います."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#文字列と文字",
    "href": "lecture/10-1-julia-intro.html#文字列と文字",
    "title": "Juliaの基礎",
    "section": "文字列と文字",
    "text": "文字列と文字\n\nString と Character\nPythonやその他のプログラミング言語と異なり, Juliaでは文字列 (String) と文字 (Character) が厳密に区別されています.\n\n文字列はダブルクォーテーション \" で囲みます.\n文字 (1文字のみ) はシングルクォーテーション ' で囲みます.\n\n\ntypeof('a')\n\nChar\n\n\n\ntypeof(\"a\")\n\nString\n\n\nそのため, 以下のようなコードで直感的でない結果が得られることがあります.\n\n\"abcd\"[3] == \"c\"\n\nfalse\n\n\n\n\"abcd\"[3] == 'c'\n\ntrue\n\n\n\n\nUnicode文字\n\nJuliaではUnicode文字を変数名として使用することができます (e.g., α, ÷, σ², x₁).\nUnicode文字は\\ + 文字列 + &lt;tab&gt;で入力することができます. (e.g., \\alpha + &lt;tab&gt;で α が入力できます.)\n使用できるUnicode文字の一覧.\n\nそのため, CRRA効用関数とその導関数を以下のようにUnicode文字を用いて簡単に書くことができます.\n\\[\n\\begin{aligned}\nu(c, \\sigma) &= \\begin{cases}\n\\log c & \\text{ if } \\sigma = 1 \\\\\n\\frac{c^{1 - \\sigma}}{1 - \\sigma} & \\text{ if } \\sigma \\ne 1\n\\end{cases}\\\\\nu'(c, \\sigma) &= c^{-\\sigma}\n\\end{aligned}\n\\]\nu(c, σ) = σ == 1.0 ? log(c) : c^(1 - σ) / (1 - σ)\nu′(c, σ) = c^(-σ)\n\n導関数 u′　の上付き文字は \\prime + &lt;tab&gt; で入力できます.\n三項演算子 ? : を用いることで, if-else文を簡潔に書くことができます. つまり上のコードは以下と等価です.\n\nfunction u(c, σ)\n    if σ == 1.0\n        return log(c)\n    else\n        return c^(1 - σ) / (1 - σ)\n    end\nend\n\n\n文字列の内挿\n\nage = 26\nyears_stay = 6\nf(years, age) = 100years ÷ (age) # ÷ returns the quotient\n\ns = \"I came here $years_stay years ago, when I was $(age - years_stay).\\nSo I spent $(f(years_stay, age)) % of my life in Madrid.\"\nprintln(s)\n\nI came here 6 years ago, when I was 20.\nSo I spent 23 % of my life in Madrid.\n\n\n\n$ + 変数名 で変数を文字列内に埋め込むことができます.\n$(式) で式を文字列内に埋め込むことができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#データ構造",
    "href": "lecture/10-1-julia-intro.html#データ構造",
    "title": "Juliaの基礎",
    "section": "データ構造",
    "text": "データ構造\n\nタプル\n\nanimals = (\"bird\", \"cow\", \"fish\")\nanimals[1]\n\n\"bird\"\n\n\n\npars = (α=1.0, β=2.0, γ=4.0)\npars.β\n\n2.0\n\n\n\nタプルは()で囲まれた要素の集まりです.\nタプルの要素は[]を用いてアクセスできます.\n名前付きタプルは=を用いて要素に名前をつけることができます.\n名前付きタプルの要素は.を用いてアクセスできます.\n\n\nfunction tuple_sum(pars)\n    (; α, γ) = pars\n    return α + γ\nend\n\ntuple_sum(pars)\n\n5.0\n\n\n\n名前付きタプルの要素は(; )を用いて, 各要素に展開することができます\n\n\n\nベクトル, 行列 (Array)\n\n[1, 2, 3]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\n\n[1 2 3]\n\n1×3 Matrix{Int64}:\n 1  2  3\n\n\n\n[1; 2; 3]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\n\nベクトルは[]で囲まれた,区切りの要素の集まりです.\n空白区切りの場合は行列 (この場合は横ベクトル)として扱われます.\n; 区切りは行列の中での改行を表します. 結果的にこの場合は縦ベクトルとして扱われます.\n\n\n[1 2; 3 4]\n\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\n\n\nA = [1 2\n    3 4]\n\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\n\n\n行列は;区切りの行ベクトルを[]で囲むことで作成できます.\nなお;の代わりに改行を入れることもできます.\n\nレンジ\n\n0:0.1:1\n\n0.0:0.1:1.0\n\n\n\nstart:step:stop でレンジを作成できます.\nstart から stop まで step ずつ増加する数列を生成します.\nステップが省略された場合はデフォルトで1になります.\n\n\nrange(0, length=11, stop=1)\n\n0.0:0.1:1.0\n\n\n\nrange(start, length = n, stop = end) で n 個の start から end までの数列を生成できます.\n\n\n\n\n\n\n\nNoteレンジとベクトルの違い\n\n\n\nJuliaにおけるレンジはベクトルではなく, イテレータです. データとしては, レンジはベクトルではなく, レンジの始点, 終点, ステップの情報を持っているだけです. そのため, 生成の際のメモリは節約できる一方, ベクトルの様に要素を参照しようとすると計算コストがかかります.\n\nr = 0:0.1:1\ntypeof(r)\n\nStepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n\n\n\ntypeof(collect(r))\n\n\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\ncollect() 関数を用いることで, レンジをベクトルに変換することができます."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#特殊記法",
    "href": "lecture/10-1-julia-intro.html#特殊記法",
    "title": "Juliaの基礎",
    "section": "特殊記法",
    "text": "特殊記法\n\n内包表記\n\n[2^i for i in 1:5]\n\n5-element Vector{Int64}:\n  2\n  4\n  8\n 16\n 32\n\n\n\n[i + j for i in 1:3, j in 1:3]\n\n3×3 Matrix{Int64}:\n 2  3  4\n 3  4  5\n 4  5  6\n\n\n\n内包表記は[ ]の中でforループを用いてベクトルや行列を生成する方法です.\n1次元の場合はforループを1つ, 2次元の場合はforループを,で区切って2つ用います.\n\n\n\nドット記法\n\nf(x) = x^2\nf.([1, 2, 3])\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\n\n定数に対して定義された関数をベクトルや行列に適用する際には, .を関数名の後につけることで各要素に適用することができます.\n\n\n[1, 2, 3] .* [4, 5, 6]\n\n3-element Vector{Int64}:\n  4\n 10\n 18\n\n\n[1, 2, 3] * [4, 5, 6] # Error\n\n[1, 2, 3]' * [4, 5, 6]\n\n32\n\n\n\n.* は要素ごとの積を計算します.\n* は行列の積を計算します. この例では縦ベクトルと縦ベクトルの積は定義できないため, エラーが発生します.\n内積を計算する場合は, 'を用いて転置を行った後に行列の積を計算します."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#plots.jlの使い方",
    "href": "lecture/10-1-julia-intro.html#plots.jlの使い方",
    "title": "Juliaの基礎",
    "section": "Plots.jlの使い方",
    "text": "Plots.jlの使い方\n\nusing Plots\n\nPlots.jlは, Juliaで図を描画するためのパッケージです. そのバックエンドとして以下の様なパッケージを統一的な文法で扱うことができます.\n\nGR: デフォルト\nPlotly: JavaScriptを利用したインタラクティブなプロット\nPyPlot: Pythonのmatplotlibを利用\nPGFPlotsX: LaTeXのpgfplotsを利用\n\nこの授業では基本的にGRを使用します. また, Plots.jl以外のパッケージとして, 近年はMakieも人気を集めています.\n\n数列のプロット\n以下の様なフィボナッチ数列をプロットしてみましょう.\n\\[\nF_n = \\begin{cases}\n1 & n = 1, 2 \\\\\nF_{n-1} + F_{n-2} & n = 3, 4, \\dots\n\\end{cases}\n\\]\n\nN = 20\nfibs = zeros(Int, N)\nfibs[1], fibs[2] = 1, 1\nfor i = 3:N\n    fibs[i] = fibs[i-1] + fibs[i-2]\nend\n\nscatter(1:N, fibs, title=\"Fibonacci Sequences\", legends=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter: 散布図を描画します.\n\n\n\n関数のプロット\n\\[\nB_n = \\begin{cases}\n\\frac{1}{n} & n \\text{ odd} \\\\\n1 - \\frac{1}{n} & n \\text{ even}\n\\end{cases}\n\\]\n\nf(n) = isodd(n) ? 1 / n : 1 - 1 / n\nscatter(1:40, f, legends=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n描画関数 (e.g, scatter) の第2引数に関数を指定することで, 第一引数の値に対する関数の値をプロットできます\n\n\n\nプロットの重ね合わせ\n\nusing LaTeXStrings\n\nf₁(x) = x^2\nf₂(x) = x\nf₃(x) = log(x)\n\nxs = 0:0.01:1\nplot(xs, f₁, label=L\"f_1(x) = x^2\", legend=:bottomright)\nplot!(xs, f₂, label=L\"f_2(x) = x\")\nplot!(xs, f₃, label=L\"f_3(x) = \\log \\,x\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot: 折れ線グラフを描画します.\n!を付けることで, 既存のプロットに追加描画します.\nscatterを追加する場合は, scatter!を使用します.\n数式をグラフに表示するためには, LaTeXStringsパッケージを使用し, L\"...\"で囲みます.\n\n\n\nレイアウト\n\nf(x, y) = (x ≠ y) ? (x + y) / (x - y) : one(x)\nxs = range(-1.0, 1.0, length=100)\nys = copy(xs)\np1 = contour(xs, ys, f)\np2 = surface(xs, ys, f)\nplot(p1, p2, layout=(1, 2))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontour: 等高線プロットを描画します.\nlayout=(1, 2): レイアウトを指定します. この場合, 1行2列のプロットを描画します.\nより複雑なレイアウトはドキュメントを参照してください."
  },
  {
    "objectID": "lecture/10-1-julia-intro.html#julia-での表の作り方",
    "href": "lecture/10-1-julia-intro.html#julia-での表の作り方",
    "title": "Juliaの基礎",
    "section": "Julia での表の作り方",
    "text": "Julia での表の作り方\n\nusing SummaryTables\n\nレポートや論文を書く際に, Juliaのコードを実行した結果を表として出力したい場合, SummaryTables.jlを用いることができます. 最も簡単な方法は simple_table() 関数を用いることですが, より複雑な票を作成することも可能です. また, 出力形式としては, HTML, LaTeX, DOCX, Typst などがサポートされています.\n\ndata = (\n    id=1:5,\n    name=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n    age=[34, 29, 42, 37, 25],\n    score=[88, 92, 75, 80, 95]\n)\n\nsimple_table(data)\n\n\n\nTable 1: An example of SummaryTables.jl\n\n\n\n\n    \n    \n    \n        id\n        name\n        age\n        score\n    \n            \n        1\n        Alice\n        34\n        88\n    \n    \n        2\n        Bob\n        29\n        92\n    \n    \n        3\n        Charlie\n        42\n        75\n    \n    \n        4\n        David\n        37\n        80\n    \n    \n        5\n        Eve\n        25\n        95"
  }
]